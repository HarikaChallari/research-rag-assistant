[CHUNK 0]
Highlights Summary of ChatGPT-Related Research and Perspective Towards the Future of Large Language Models Yiheng Liu∗,Tianle Han∗,Siyuan Ma,Jiayue Zhang,Yuanyuan Yang,Jiaming Tian,Hao He,Antong Li,Mengshen He,Zhengliang Liu,Zihao Wu,Lin Zhao,Dajiang Zhu,Xiang Li,Ning Qiang,Dingang Shen,Tianming Liu,Bao Ge •A comprehensive survey of ChatGPT-related research. •Analysis of 194 research papers. •Pavingthewayforfurtherresearchandexplorationinleveraginglargelanguagemodelsforvariousapplications.arXiv:2304.01852v4 [cs.CL] 22 Aug 2023Summary of ChatGPT-Related Research and Perspective Towards the Future of Large Language Models Yiheng Liu∗a, Tianle Han∗a, Siyuan Maa, Jiayue Zhanga, Yuanyuan Yanga, Jiaming Tiana, Hao Hea, Antong Lib, Mengshen Hea, Zhengliang Liuc, Zihao Wuc, Lin Zhaoc, Dajiang Zhud, Xiang Lie, Ning Qianga, Dingang Shenf,g,h, Tianming Liucand Bao Gea aSchool of Physics and Information Technology, Shaanxi Normal University, Xi’an, 710119, Shaanxi, China bSchool of Life and Technology Biomedical-Engineering, Xi’an Jiaotong University, Xi’an, 710119, Shaanxi, China cSchool of Computing, The University of Georgia, Athens, 30602, USA dDepartment of Computer Science and Engineering, The University of Texas at Arlington, Arlington, 76019, USA eDepartment of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, 02115, USA fSchool of Biomedical Engineering, ShanghaiTech University, Shanghai, 201210, China gShanghai United Imaging Intelligence Co., Ltd., Shanghai, 200230, China hShanghai Clinical Research and Trial Center, Shanghai, 201210, China ABSTRACT ThispaperpresentsacomprehensivesurveyofChatGPT-related(GPT-3.5andGPT-4)research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applicationsacrossdiversedomains.Indeed,keyinnovationssuchaslarge-scalepre-trainingthat capturesknowledgeacrosstheentireworldwideweb,instructionfine-tuningandReinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs’ adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education andhistorytomathematics,medicine,andphysics.Thisstudyendeavorstofurnishinsightsinto ChatGPT’s capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field. 1. Introduction Recent advances in natural language processing (NLP) have led to the development of powerful language models such as the GPT (Generative Pre-trained Transformer) series [79; 81; 80; 8; 73], including large language models (LLM) such as ChatGPT (GPT-3.5 and GPT-4) [71]. These models are pre-trained on vast amounts of text data and have demonstrated exceptional performance in a wide range of NLP tasks, including language translation, text summarization, and question-answering. In particular, the ChatGPT model has demonstrated its potential in various fields,includingeducation,healthcare,reasoning,textgeneration,human-machineinteraction,andscientificresearch. A key milestone of LLM development is InstructGPT [73], a framework that allows for instruction fine-tuning of a pre-trained language model based on Reinforcement Learning from Human Feedback (RLHF) [11; 73]. This framework enables an LLM to adapt to a wide range of NLP tasks, making it highly versatile and flexible by leveraging human feedback. RLHF enables the model to align with human preferences and human values, which significantly improves from large language models that are solely trained text corpora through unsupervised pre- training.ChatGPTisasuccessortoInstructGPT.SinceitsreleaseinDecember2022,ChatGPThasbeenequippedwith theseadvanceddevelopments,leadingtoimpressiveperformancesinvariousdownstreamNLPtaskssuchasreasoning and generalized text generation. These unprecedented NLP capabilities spur applications in diverse domains such as education,healthcare,human-machineinteraction,medicineandscientificresearch.ChatGPThasreceivedwidespread attentionandinterest,leadingtoanincreasingnumberofapplicationsandresearchthatharnessitsexceedingpotential. ∗These authors contributed equally to this work. ∗ ∗Corresponding author ORCID(s): Yiheng Liu et al.: Preprint submitted to Elsevier Page 1 of 21Summary of ChatGPT-Related Research Figure 1: The graphical representation is utilized to depict the number of research articles related to ChatGPT published from 2022 to April, 2023, revealing the trend and growth of ChatGPT-related research over time. The graph showcases the monthly count of submissions and cumulative daily submitted count in arXiv. Over time, there has been an increasing amount of research related to ChatGPT. Theopenreleaseofthemulti-modalGPT-4modelfurtherexpandsthehorizonoflargelanguagemodelsandempowers exciting developments that involve diverse data beyond text. ThepurposeofthispaperistoprovideacomprehensivesurveyoftheexistingresearchonChatGPTanditspotential applications in various fields. To achieve this goal, we conducted a thorough analysis of papers related to ChatGPT in the arXiv repository. As of April 1st, 2023, there are a total of 194 papers mentioning ChatGPT on arXiv. In this study,weconductedatrendanalysisofthesepapersandgeneratedawordcloudtovisualizethecommonlyusedterms. Additionally, we also examined the distribution of the papers across various fields and presented the corresponding statistics. Figure 1 displays the submission trend of papers related to ChatGPT, indicating a growing interest in this field.Figure2illustratesthewordcloudanalysisofallthepapers.Wecanobservethatthecurrentresearchisprimarily focused on natural language processing, but there is still significant potential for research in other fields such as education, medical and history. This is further supported by Figure 3, which displays the distribution of submitted papersacrossvariousfields,highlightingtheneedformoreresearchanddevelopmentintheseareas.Duetotherapid advancement in research related to ChatGPT, we have also introduced a dynamic webpage that provides real-time updates on the latest trends in these area. Interested readers can access the webpage and stay informed about the evolving research directions by following this link1. This paper aims to shed light on the promising capabilities of ChatGPT and provide insight into its potential impactinthefuture,includingethicalconsiderations.Throughthissurvey,wehopetoprovideinsightsintohowthese modelscanbeimprovedandextendedinthefuture.Insection2,wewillreviewtheexistingworkrelatedtoChatGPT, including its applications and ethical considerations. In section 3, we conducted a review of existing literature that assesses the capabilities of ChatGPT. We comprehensively evaluated the performance of ChatGPT based on these studies. In addition to discussing the current state of research related to ChatGPT, we will also explore its limitations in section 4. Furthermore,

[CHUNK 1]
a total of 194 papers mentioning ChatGPT on arXiv. In this study,weconductedatrendanalysisofthesepapersandgeneratedawordcloudtovisualizethecommonlyusedterms. Additionally, we also examined the distribution of the papers across various fields and presented the corresponding statistics. Figure 1 displays the submission trend of papers related to ChatGPT, indicating a growing interest in this field.Figure2illustratesthewordcloudanalysisofallthepapers.Wecanobservethatthecurrentresearchisprimarily focused on natural language processing, but there is still significant potential for research in other fields such as education, medical and history. This is further supported by Figure 3, which displays the distribution of submitted papersacrossvariousfields,highlightingtheneedformoreresearchanddevelopmentintheseareas.Duetotherapid advancement in research related to ChatGPT, we have also introduced a dynamic webpage that provides real-time updates on the latest trends in these area. Interested readers can access the webpage and stay informed about the evolving research directions by following this link1. This paper aims to shed light on the promising capabilities of ChatGPT and provide insight into its potential impactinthefuture,includingethicalconsiderations.Throughthissurvey,wehopetoprovideinsightsintohowthese modelscanbeimprovedandextendedinthefuture.Insection2,wewillreviewtheexistingworkrelatedtoChatGPT, including its applications and ethical considerations. In section 3, we conducted a review of existing literature that assesses the capabilities of ChatGPT. We comprehensively evaluated the performance of ChatGPT based on these studies. In addition to discussing the current state of research related to ChatGPT, we will also explore its limitations in section 4. Furthermore, we will provide guidance on future directions for language model development. 2. Related work of ChatGPT In this section, we review the latest research related to the application and ethics of ChatGPT. Figure 4 shows the overall framework of this part. 1https://snnubiai.github.io/chatgpt_arxiv_analysis/ Yiheng Liu et al.: Preprint submitted to Elsevier Page 2 of 21Summary of ChatGPT-Related Research Figure 2: Word cloud analysis of all the 194 papers. 2.1. Application of ChatGPT 2.1.1. Question And Answering In the field of education ChatGPT is commonly used for question and answers testing in the education sector. Users can use ChatGPT to learn,compareandverifyanswersfordifferentacademicsubjectssuchasphysics,mathematics,andchemistry,and/or conceptual subjects such as philosophy and religion. Additionally, users can ask open-ended and analytical questions to understand the capabilities of ChatGPT. In the field of mathematics, Frieder et al. [17] constructed the GHOSTS natural language dataset, which consists of graduate-level math test questions. The authors tested ChatGPT’s math abilities on the GHOSTS dataset using a question-and-answer format and evaluated it according to fine-grained standards.In the Grad Text dataset, which coverssimplesettheoryandlogicproblems,ChatGPTperformedthebest.However,intheOlympiad-Problem-Solving dataset,ChatGPTperformedpoorly,receivingonlytwo4-pointscores(outofatotalof5),withthemajorityofscores being 2 points. In the Holes-in-Proofs dataset, ChatGPT received the lowest score of 1 point. In the MATH dataset, ChatGPT only scored impressively in 26% of cases. These results suggest that ChatGPT’s math abilities are clearly lower than those of ordinary math graduate students. Although ChatGPT can generally understand math problems, it failstoprovidethecorrectsolutions.Pardosetal.[74]usedtheOpenAdaptiveTutoringsystem(OATutor)toinvestigate whether prompts generated by ChatGPT were helpful for learning algebra, with 77 participants from Mechanical Turk taking part in the experiment. The experiment used questions from OpenStax’s Elementary and Intermediate Algebra textbooks. These participants were randomly assigned to either a control group (with manual prompts) or an experimental group (with ChatGPT prompts). For each question in both courses, the authors obtained answers from ChatGPT through a question-and-answer format and evaluated scores according to three criteria: ChatGPT provided an answer, the answer was correct, and inappropriate language was not used in the answer. The study found that 70% of prompts generated by ChatGPT passed manual quality checks, and both humans and ChatGPT produced positive learninggains.However,thescoresofhumanpromptsrangedfrom74.59%to84.32%,significantlyhigherthanthose of ChatGPT prompts. Shakarian et al. [82] studied the performance of ChatGPT on math word problems (MWPs), using the DRAW-1K dataset for experimentation. The dataset consists of 1000 MWPs and their answers, along with algebraic equation templates for solving such problems. The authors used the idea of machine learning introspection andbuiltperformancepredictionmodelsusingrandomforestsandXGBoost,andevaluatedthemonthedatasetusing Yiheng Liu et al.: Preprint submitted to Elsevier Page 3 of 21Summary of ChatGPT-Related Research Figure 3: The distribution of submitted papers across various fields. five-foldcross-validation.ChatGPT’saccuracyincreasedfromaninitial34%toafinal69%,whileitsrecallincreased from an initial 41% to a final 83%. The authors also found that ChatGPT’s failure rate decreased from an initial 84% to a final 20%, indicating that performance can vary greatly depending on specific job requirements. In the field of physics, Lehnert et al. [48] explored the capabilities and limitations of ChatGPT by studying how it handles obscure physics topics such as the swamp land conjecture in string theory. The experimental dialogue beganwithbroader andmoregeneralquestionsinthe fieldofstringtheorybefore narrowingdowntospecificswamp land conjectures and examining ChatGPT’s understanding of them. The study found that ChatGPT could define and explain different concepts in various styles, but was not effective in truly connecting various concepts. It would confidently provide false information and fabricate statements when necessary, indicating that ChatGPT cannot truly createnewknowledgeorestablishnewconnections.However,intermsofidentifyinganalogiesanddescribingabstract concepts of visual representation, ChatGPT can cleverly use language. Kortemeyer et al. [44] evaluated ChatGPT’s ability to answer calculus-based physics questions through a question-and-answer test. The tests included online homework, clicker questions, programming exercises, and exams covering classical mechanics, thermodynamics, electricity and magnetism, and modern physics. While ChatGPT was able to pass the course, it also demonstrated many misconceptions and errors commonly

[CHUNK 2]
of ChatGPT-Related Research Figure 3: The distribution of submitted papers across various fields. five-foldcross-validation.ChatGPT’saccuracyincreasedfromaninitial34%toafinal69%,whileitsrecallincreased from an initial 41% to a final 83%. The authors also found that ChatGPT’s failure rate decreased from an initial 84% to a final 20%, indicating that performance can vary greatly depending on specific job requirements. In the field of physics, Lehnert et al. [48] explored the capabilities and limitations of ChatGPT by studying how it handles obscure physics topics such as the swamp land conjecture in string theory. The experimental dialogue beganwithbroader andmoregeneralquestionsinthe fieldofstringtheorybefore narrowingdowntospecificswamp land conjectures and examining ChatGPT’s understanding of them. The study found that ChatGPT could define and explain different concepts in various styles, but was not effective in truly connecting various concepts. It would confidently provide false information and fabricate statements when necessary, indicating that ChatGPT cannot truly createnewknowledgeorestablishnewconnections.However,intermsofidentifyinganalogiesanddescribingabstract concepts of visual representation, ChatGPT can cleverly use language. Kortemeyer et al. [44] evaluated ChatGPT’s ability to answer calculus-based physics questions through a question-and-answer test. The tests included online homework, clicker questions, programming exercises, and exams covering classical mechanics, thermodynamics, electricity and magnetism, and modern physics. While ChatGPT was able to pass the course, it also demonstrated many misconceptions and errors commonly held by beginners. West et al. [98] used the Force Concept Inventory Yiheng Liu et al.: Preprint submitted to Elsevier Page 4 of 21Summary of ChatGPT-Related Research Related work of ChatGPT Application of ChatGPT AI Ethics Question And Answering Text Classification Data or information extraction , transformation , enhancement , processing Inference Text Generation Code Generation Human -ChatGPT Collaboration ChatGPT Integration Medical Applications Figure 4: Structure Diagram of Chapter 2. (FCI) to evaluate ChatGPT’s accuracy in answering physics concept problems related to kinematics and Newtonian mechanics in the first semester of college physics. The FCI covers topics such as kinematics, projectile motion, free fall, circular motion, and Newton’s laws. The study included data from 415 students who took the FCI at the end of the semester, with an average score of 56%, while ChatGPT scored approximately between 50% to 65%. The authors demonstratedthatChatGPT’sperformanceinphysicslearningcanreachorevenexceedtheaveragelevelofasemester of college physics. In the medical field ChatGPT’squestion-answeringcapabilitiescanalsobeappliedinthemedicalfield,suchasforansweringmedical questions from patients or assisting healthcare professionals in diagnosing diseases. Nov et al. [70] evaluated the feasibility of using ChatGPT for patient-doctor communication. The experiment extracted 10 representative patient- doctorinteractionsfromEHR,placedthepatient’squestionsinChatGPT,andaskedChatGPTtorespondusingroughly the same number of words as the doctor’s response. Each patient’s question was answered by either the doctor or ChatGPT, and the patient was informed that 5 were answered by the doctor and 5 were generated by ChatGPT, and was asked to correctly identify the source of the response. The results of the experiment showed that the probability of correctly identifying ChatGPT’s response was 65.5%, while the probability of correctly identifying the doctor’s responsewas65.1%.Inaddition,theexperimentfoundthatthepatient’sresponsetothetrustworthinessofChatGPT’s functionwasweaklypositive(averageLikertscore:3.4),andtrustdecreasedasthecomplexityofhealth-relatedtasks inthequestionsincreased.ChatGPT’sresponsestopatientquestionswereonlyslightlydifferentfromthoseofdoctors, but people seem to trust ChatGPT to answer low-risk health questions, while for complex medical questions, people still tend to trust the doctor’s responses and advice. Tu et al. [91] explored the causal discovery ability of ChatGPT in the diagnosis of neuropathic pain. Causal relationship discovery aims to reveal potential unknown causal relationships based purely on observed data [20]. The experimentalresultsfoundthatChatGPThassomelimitationsinunderstandingnewknowledgeandconceptsbeyond the existing textual training data corpus, that is, it only understands language commonly used to describe situations and not underlying knowledge. In addition, its performance consistency and stability are not high, as the experiment observed that it would provide different answers for the same question under multiple inquiries. However, despite the many limitations of ChatGPT, we believe that it has a great opportunity to improve causal relationship research. Yiheng Liu et al.: Preprint submitted to Elsevier Page 5 of 21Summary of ChatGPT-Related Research In other fields Guoetal.[23]attemptedtoapplyChatGPTinthefieldofcommunication,specificallyusingChatGPTforordered importance semantic communication, where ChatGPT plays the role of an intelligent consulting assistant that can replace humans in identifying the semantic importance of words in messages and can be directly embedded into the currentcommunicationsystem.Foramessagetobetransmitted,thesenderfirstutilizesChatGPTtooutputthesemantic importanceorderofeachword.Then,thetransmitterexecutesanunequalerrorprotectiontransmissionstrategybased ontheimportanceordertomakethetransmissionofimportantwordsinthemessagemorereliable.Theexperimental resultsshowthattheerrorrateandsemanticlossofimportantwordsmeasuredinthecommunicationsystemembedded with ChatGPT are much lower than those of existing communication schemes, indicating that ChatGPT can protect important words well and make semantic communication more reliable. Wang et al. [95] studied the effectiveness of ChatGPT in generating high-quality Boolean queries for systematic literature search. They designed a wide range of prompts and investigated these tasks on more than 100 systematic review topics. In the end, queries generated by ChatGPT achieved higher accuracy compared to the currently most advanced query generation methods but at the cost of reduced recall. For time-limited rapid reviews, it is often acceptable to trade off higher precision for lower recall. Additionally, ChatGPT can generate high search accuracy Boolean queries by guiding the prompts. However, it should be noted that when two queries use the same prompts,ChatGPTgeneratesdifferentqueries,indicatingitslimitationsinconsistencyandstability.Overall,thisstudy demonstrated the potential of ChatGPT in generating effective Boolean queries for systematic literature searches. 2.1.2. Text Classification The purpose of text classification is to assign text data to predefined

[CHUNK 3]
Research In other fields Guoetal.[23]attemptedtoapplyChatGPTinthefieldofcommunication,specificallyusingChatGPTforordered importance semantic communication, where ChatGPT plays the role of an intelligent consulting assistant that can replace humans in identifying the semantic importance of words in messages and can be directly embedded into the currentcommunicationsystem.Foramessagetobetransmitted,thesenderfirstutilizesChatGPTtooutputthesemantic importanceorderofeachword.Then,thetransmitterexecutesanunequalerrorprotectiontransmissionstrategybased ontheimportanceordertomakethetransmissionofimportantwordsinthemessagemorereliable.Theexperimental resultsshowthattheerrorrateandsemanticlossofimportantwordsmeasuredinthecommunicationsystemembedded with ChatGPT are much lower than those of existing communication schemes, indicating that ChatGPT can protect important words well and make semantic communication more reliable. Wang et al. [95] studied the effectiveness of ChatGPT in generating high-quality Boolean queries for systematic literature search. They designed a wide range of prompts and investigated these tasks on more than 100 systematic review topics. In the end, queries generated by ChatGPT achieved higher accuracy compared to the currently most advanced query generation methods but at the cost of reduced recall. For time-limited rapid reviews, it is often acceptable to trade off higher precision for lower recall. Additionally, ChatGPT can generate high search accuracy Boolean queries by guiding the prompts. However, it should be noted that when two queries use the same prompts,ChatGPTgeneratesdifferentqueries,indicatingitslimitationsinconsistencyandstability.Overall,thisstudy demonstrated the potential of ChatGPT in generating effective Boolean queries for systematic literature searches. 2.1.2. Text Classification The purpose of text classification is to assign text data to predefined categories. This task is critical for many applications, including sentiment analysis, spam detection, and topic modeling. While traditional machine learning algorithmshavebeenwidelyusedfortextclassification,recentadvancesinnaturallanguageprocessinghaveledtothe developmentofmoreadvancedtechniques.ChatGPThasshownimmensepotentialinthisfield.Itsabilitytoaccurately classifytext,flexibilityinhandlingvariousclassificationtasks,andpotentialforcustomizationmakeitavaluabletool for text classification, as evidenced by several studies in the literature. Kuzman et al. [46] employed ChatGPT for automated genre recognition, with the goal of simplifying the text classification task by utilizing ChatGPT’s zero-shot classification capability. They compared ChatGPT’s genre recognition performance, using two prompt languages (EN and SL), with the X-GENRE classifier based on the multilingualmodelXLM-RoBERTaontheEnglishdatasetEN-GINCOandtheSloveniandatasetGINCO.Theresults showedthatwhenENwasusedasthepromptlanguage,ChatGPTachievedMicroF1,MacroF1,andAccuracyscores of0.74,0.66,and0.72.However,ontheGINCOdataset,ChatGPT’sgenrerecognitionperformancewithbothENand SL prompt languages was lower than that of the X-GENRE classifier to varying degrees. Amin et al. [2] evaluated the text classification ability of ChatGPT in affective computing by using it to performpersonalityprediction,sentimentanalysis,andsuicideideationdetectiontasks.TheypromptedChatGPTwith correspondingpromptsonthreedatasets:FirstImpressions,Sentiment140,andSuicideandDepression,andcompared its classification performance with three baseline models: RoBERTa-base, Word2Vec, and BoW. The results showed that ChatGPT’s accuracy and UAR for the five personality classifications on the First Impressions dataset were lower than the baseline methods to varying degrees. On the Sentiment140 dataset, ChatGPT’s accuracy and UAR were 85.5and85.5,respectively,whichwerebetterthanthethreebaselinemethods.OntheSuicideandDepressiondataset, ChatGPT’saccuracyandUARwere92.7and91.2,respectively,whichwerelowerthanRoBERTa,thebest-performing baseline method. Zhang et al. [106] employed ChatGPT for stance detection, which includes support and opposition. They used ChatGPTtoclassifythepoliticalstanceoftweetsintheSemEval-2016andP-Stancedatasets.SemEval-2016contains 4,870Englishtweets,andtheyselectedtweetswiththemostcommonlyoccurringFM,LA,andHCpoliticallabelsfor stance classification. TheP-Stance dataset has 21,574English tweets, and theyclassified the stance of tweetstowards Trump,Biden,andBernie.ThefinalresultsshowedthatontheSemEval-2016dataset,ChatGPTachievedF1-mscores of68.4,58.2,and79.5fortheFM,LA,andHCpoliticallabels,andF1-avgscoresof72.6,59.3,and78.0,respectively. On the P-Stance dataset, ChatGPT achieved F1-m scores of 82.8, 82.3, and 79.4 for the Trump, Biden, and Bernie political figures, and F1-avg scores of 83.2, 82.0, and 79.4, respectively. Huang et al. [32] used ChatGPT to detect implicit hate speech in tweets. They selected 12.5% (795 tweets) of the LatentHatreddatasetcontainingimplicithatespeechandaskedChatGPTtoclassifythemintothreecategories:implicit hatespeech,non-hatespeech,anduncertain.TheresultsshowedthatChatGPTcorrectlyrecognized636(80%)ofthe Yiheng Liu et al.: Preprint submitted to Elsevier Page 6 of 21Summary of ChatGPT-Related Research tweets.Thenumberoftweetsclassifiedasnon-hatespeechanduncertainwere146(18.4%)and13(1.6%),respectively. The results of the reclassification of tweets in the non-hate speech and uncertain categories by Amazon Mechanical Turk (Mturk) workers were consistent with ChatGPT’s classification. Overall,ChatGPThastremendouspotentialintextclassificationtasks,asitcaneffectivelyaddressproblemssuch asgenreidentification,sentimentanalysis,stancedetection,andmore.However,therearestillchallengesthatChatGPT faces in the field of text classification. Firstly, it struggles to perform well in classification tasks with rare or out-of- vocabularywordssinceitheavilyreliesonthedistributionoftrainingdata.Additionally,thesignificantcomputational resources required for training and utilizing ChatGPT can limit its use in some applications. 2.1.3. Text Generation We live in an era of information explosion, and text is an efficient way of transmitting information. The diversity of information has led to a diversity of text categories. When researchers use ChatGPT’s text generation capabilities for research, they inevitably choose to generate different types of text. In the process of reading papers, we found that thewordcountofthetextgeneratedbyresearchersincreasedfromsmalltolarge,sowewantedtosummarizeexisting research based on the size of the text word count. We divided the generated text into three levels: phrases, sentences, and paragraphs. The following article uses ChatGPT to generate phrases. Zhang et al. [107] proves that the semantic HAR model withsemanticaugmentationaddedduringtrainingperformsbetterinmotionrecognitionthanothermodels.Semantic augmentation requires shared tokens, which is lacking in some datasets. Therefore, authors leverage ChatGPT for an automated label generation approach for datasets originally without shared tokens. Fu et al. [18] described a new workflow for converting natural language commands into Bash commands. The author uses ChatGPT to generate a candidate list of Bash commands based on user input, and then uses a combination of heuristic and machine learning techniquestorankandselectthemostlikelycandidates.Thisworkflowwasevaluatedonarealcommanddatasetand achievedhighaccuracycomparedtootherstate-of-the-artmethods.Chenetal.[10]usedtheBartmodelandChatGPT for the task of summarizing humorous titles and compared the performance of the two models. It was found that the Bartmodelperformedbetteronlargedatasets,butChatGPTwascompetitivewithourbestfine-tunedmodelinasmall range (48), albeit slightly weaker. ThefollowingarticleusesChatGPTtogeneratesentences.Chenetal.[9]constructedadialoguedataset(HPD)with scenes,timelines,characterattributes,andcharacterrelationshipsinordertouseChatGPTasaconversationalagentto generate dialogue. However, ChatGPT’s performance on the test set was poor, and there is room for improvement.In study[36],chatGPTdemonstrateditsabilitytosimplifycomplextextbyprovidingthreefictionalradiologyreportsto chatGPTforsimplification.Mostradiologistsfoundthesimplifiedreportstobeaccurateandcomplete,withnopotential harm to patients. However, some errors, omissions of critical medical information and text passages were identified, which could potentially lead to harmful conclusions if not understood by the physicians. Xia et al. [102] proposed a new program repair paradigm called Session-based Automated Program Repair (APR). In APR, the previously generated patches are

[CHUNK 4]
We divided the generated text into three levels: phrases, sentences, and paragraphs. The following article uses ChatGPT to generate phrases. Zhang et al. [107] proves that the semantic HAR model withsemanticaugmentationaddedduringtrainingperformsbetterinmotionrecognitionthanothermodels.Semantic augmentation requires shared tokens, which is lacking in some datasets. Therefore, authors leverage ChatGPT for an automated label generation approach for datasets originally without shared tokens. Fu et al. [18] described a new workflow for converting natural language commands into Bash commands. The author uses ChatGPT to generate a candidate list of Bash commands based on user input, and then uses a combination of heuristic and machine learning techniquestorankandselectthemostlikelycandidates.Thisworkflowwasevaluatedonarealcommanddatasetand achievedhighaccuracycomparedtootherstate-of-the-artmethods.Chenetal.[10]usedtheBartmodelandChatGPT for the task of summarizing humorous titles and compared the performance of the two models. It was found that the Bartmodelperformedbetteronlargedatasets,butChatGPTwascompetitivewithourbestfine-tunedmodelinasmall range (48), albeit slightly weaker. ThefollowingarticleusesChatGPTtogeneratesentences.Chenetal.[9]constructedadialoguedataset(HPD)with scenes,timelines,characterattributes,andcharacterrelationshipsinordertouseChatGPTasaconversationalagentto generate dialogue. However, ChatGPT’s performance on the test set was poor, and there is room for improvement.In study[36],chatGPTdemonstrateditsabilitytosimplifycomplextextbyprovidingthreefictionalradiologyreportsto chatGPTforsimplification.Mostradiologistsfoundthesimplifiedreportstobeaccurateandcomplete,withnopotential harm to patients. However, some errors, omissions of critical medical information and text passages were identified, which could potentially lead to harmful conclusions if not understood by the physicians. Xia et al. [102] proposed a new program repair paradigm called Session-based Automated Program Repair (APR). In APR, the previously generated patches are iteratively built upon by combining them with validation feedback to construct the model’s input. The effectiveness of the approach is verified using the QuixBugs dataset. The experiment shows that ChatGPT fine-tuned with reinforcement learning from human feedback (RLHF) outperforms Codex trained unsupervisedly in both repair datasets. In reference to study [37], ChatGPT was compared to three commercial translation products: Google Translate2, DeepL Translate3, and Tencent TranSmart4. The evaluation was conducted on the Flores101 test set, using the WMT19 biomedical translation task to test translation robustness, with BLEU score as the main metric.ThestudyfoundthatChatGPTiscompetitivewithcommercialtranslationproductsonhigh-resourceEuropean languages but falls behind on low-resource or distant languages. The authors explored an interesting strategy called pivot prompts, which significantly improved translation performance. While ChatGPT did not perform as well as commercial systems on biomedical abstracts or Reddit comments, it may be a good speech translator. Prieto et al. [77] evaluated the use of ChatGPT in developing an automated construction schedule based on natural language prompts. The experiment required building new partitions in an existing space and providing details on the rooms to be partitioned. The results showed that ChatGPT was able to generate a coherent schedule that followed a logical approachtomeettherequirementsofthegivenscope.However,therewerestillseveralmajorflawsthatwouldlimitthe use of this tool in real-world projects.Michail et al. [65] proposed a method to improve the prediction accuracy of the HeFit fine-tuned XLM_T model on tweet intimacy by generating a dataset of tweets with intimacy rating tags using ChatGPT. The specific operation is to input tweets with intimacy rating tags into ChatGPT and then output similar tweets. Yiheng Liu et al.: Preprint submitted to Elsevier Page 7 of 21Summary of ChatGPT-Related Research ThefollowingarticleusesChatGPTtogenerateparagraphs.Wangetal.[92]comparedtheabstractsummarization performanceofChatGPTandothermodelsonvariouscross-lingualtextdatasetsandfoundthatChatGPTmayperform worse in metrics such as R_1, R_2, R_L, and B_S. Yang et al. [103] summarized the performance of ChatGPT in questionanswering-basedtextsummarizationandfoundthat,comparedtofine-tunedmodels,ChatGPT’sperformance is slightly worse in all performance metrics. However, the article suggests that if the dataset is golden annotation, ChatGPT’s performance may surpass fine-tuned models in these metrics. Belouadi et al. [5] compared the ability of ByGPT5andChatGPTtrainedonarangeoflabeledandunlabeleddatasetsofEnglishandGermanpoetrytogenerate constrained style poetry, and evaluated them using three metrics: Rhyme, ScoreAlliteration, and ScoreMeter Score. TheconclusionisthatByGPT5performsbetterthanChatGPT.Blanco-Gonzalezetal.[6]evaluatedchatGPT’sability to write commentary articles, and in fact, this article itself was written by chatGPT. The human author rewrote the manuscript based on chatGPT’s draft. Experts found that it can quickly generate and optimize text, as well as help users complete multiple tasks. However, in terms of generating new content, it is not ideal. Ultimately, it can be said that without strong human intervention, chatGPT is not a useful tool for writing reliable scientific texts. It lacks the knowledgeandexpertiserequiredtoaccuratelyandfullyconveycomplexscientificconceptsandinformation.Khalilet al.[39]ontheoriginalityofcontentgeneratedbyChatGPT.Toevaluatetheoriginalityof50papersonvarioustopics generatedbyChatGPT,twopopularplagiarismdetectiontools,TurnitinandiThenticate,wereused.Theresultsshowed thatChatGPThasgreatpotentialingeneratingcomplextextoutputthatisnoteasilycapturedbyplagiarismdetection software.Theexistingplagiarismdetectionsoftwareshouldupdatetheirplagiarismdetectionengines.Basicetal.[4] conducted a comparison of the writing performance of students using or not using ChatGPT-3 as a writing aid. The experimentconsistedoftwogroupsof9participantseach.Thecontrolgroupwrotearticlesusingtraditionalmethods, while the experimental group used ChatGPT as an aid. Two teachers evaluated the papers. The study showed that the assistance of ChatGPT did not necessarily improve the quality of the students’ essays.Noever et al. [68] discusses the potential of using artificial intelligence (AI), particularly language models like GPT (including GPT-3), to create more convincing chatbots that can deceive humans into thinking they are interacting with another person. The article describes a series of experiments in which they used GPT-3 to generate chatbot responses that mimic human-like conversationsandweretestedonhumanparticipants.Theresultsshowthatsomeparticipantswereunabletodistinguish betweenthechatbotandarealhuman,highlightingthepotentialfortheseAIchatbotstobeusedfordeceptivepurposes. 2.1.4. Code Generation Code generation refers to the process of automatically generating computer code from high-level descriptions or specifications. ChatGPT’s advanced natural language processing capabilities make it capable of performing code generation tasks. By analyzing the requirements for code generation, ChatGPT can produce code snippets that accurately execute the intended functionality. This not only saves time and effort in writing code from scratch but alsoreducestheriskoferrorsthatmayoccurduringmanualcoding.Inaddition,ChatGPT’sabilitytolearnandadapt tonewprogramminglanguagesandframeworksenablesittocompletemorecomplexprogrammingtasks.Forexample: Megahed et al. [64]

[CHUNK 5]
strong human intervention, chatGPT is not a useful tool for writing reliable scientific texts. It lacks the knowledgeandexpertiserequiredtoaccuratelyandfullyconveycomplexscientificconceptsandinformation.Khalilet al.[39]ontheoriginalityofcontentgeneratedbyChatGPT.Toevaluatetheoriginalityof50papersonvarioustopics generatedbyChatGPT,twopopularplagiarismdetectiontools,TurnitinandiThenticate,wereused.Theresultsshowed thatChatGPThasgreatpotentialingeneratingcomplextextoutputthatisnoteasilycapturedbyplagiarismdetection software.Theexistingplagiarismdetectionsoftwareshouldupdatetheirplagiarismdetectionengines.Basicetal.[4] conducted a comparison of the writing performance of students using or not using ChatGPT-3 as a writing aid. The experimentconsistedoftwogroupsof9participantseach.Thecontrolgroupwrotearticlesusingtraditionalmethods, while the experimental group used ChatGPT as an aid. Two teachers evaluated the papers. The study showed that the assistance of ChatGPT did not necessarily improve the quality of the students’ essays.Noever et al. [68] discusses the potential of using artificial intelligence (AI), particularly language models like GPT (including GPT-3), to create more convincing chatbots that can deceive humans into thinking they are interacting with another person. The article describes a series of experiments in which they used GPT-3 to generate chatbot responses that mimic human-like conversationsandweretestedonhumanparticipants.Theresultsshowthatsomeparticipantswereunabletodistinguish betweenthechatbotandarealhuman,highlightingthepotentialfortheseAIchatbotstobeusedfordeceptivepurposes. 2.1.4. Code Generation Code generation refers to the process of automatically generating computer code from high-level descriptions or specifications. ChatGPT’s advanced natural language processing capabilities make it capable of performing code generation tasks. By analyzing the requirements for code generation, ChatGPT can produce code snippets that accurately execute the intended functionality. This not only saves time and effort in writing code from scratch but alsoreducestheriskoferrorsthatmayoccurduringmanualcoding.Inaddition,ChatGPT’sabilitytolearnandadapt tonewprogramminglanguagesandframeworksenablesittocompletemorecomplexprogrammingtasks.Forexample: Megahed et al. [64] discussed the potential of using ChatGPT for tasks such as code explanation, suggesting alternative methods for problem-solving with code, and translating code between programming languages. The solutions provided by ChatGPT were found to be viable. In another study, Treude et al. [90] introduced a ChatGPT- based prototype called GPTCOMCARE, which helps programmers generate multiple solutions for a programming problem and highlight the differences between each solution using colors.Sobania et al. [83] utilized ChatGPT for codebugfixing,andfurtherimprovedthesuccessrateofbugfixingbyinputtingmoreinformationthroughitsdialogue system.Specifically,theQuixBugsstandardbugfixingbenchmarkcontained40codebugsthatneededtobefixed.With limitedinformation,ChatGPTfixed19bugs,whichwasslightlylowerthanthe21bugsfixedbytheCodexmodel,but significantlyhigherthanthe7fixedbytheStandardAPRmodel.Whengivenmorepromptsandinformation,ChatGPT wasabletofix31bugs,demonstratingitspotentialforcodebugfixingtasks.Xiaetal.[102]proposedaconversational approach for Automated Program Repair (APR), which alternates between generating patches and validating them against feedback from test cases until the correct patch is generated. Selecting 30 bugs from the QuixBugs standard bug fixing benchmark, which are suitable for test case feedback, and demonstrating them with Java and Python, the QuixBugs-PythonandQuixBugs-Javadatasetswereobtained.TheconversationalAPRusingChatGPToutperformed theconversationalAPRusingCodexandtheconversationalAPRusingCODEGEN(withmodelparametersof350M, 2B,6B,and16B)onbothdatasets.Furthermore,ChatGPT’sconversationalAPRgeneratedandvalidatedpatcheswith significantly fewer feedback loops than the other models. Yiheng Liu et al.: Preprint submitted to Elsevier Page 8 of 21Summary of ChatGPT-Related Research ChatGPT can not only be used to achieve some simple code generation tasks but also can be used to accomplish some complex programming tasks. Noever et al. [69] tested ChatGPT’s code generation capabilities on four datasets - Iris, Titanic, Boston Housing, and Faker. When prompted to mimic a Python interpreter in the form of a Jupyter notebook, the model was able to generate independent code based on the prompt and respond with the expected output.Forexample,whengiventheprompt"data.cor()"fortheIrisdataset,ChatGPTgeneratedcorrectPythonoutput. The test results indicate that ChatGPT can access structured datasets and perform basic software operations required by databases, such as create, read, update, and delete (CRUD). This suggests that cutting-edge language models like ChatGPThavethenecessaryscaletotacklecomplexproblems.McKeeetal.[62]utilizedChatGPTasanexperimental platformtoinvestigatecybersecurityissues.Theymodeledfivedifferentmodesofcomputervirusproperties,including self-replication,self-modification,execution,evasion,andapplication,usingChatGPT.Thesefivemodesencompassed thirteenencodingtasksfromcredentialaccesstodefenseevasionwithintheMITREATT&CKframework.Theresults showedthatthequalityofChatGPT’sgeneratedcodewasgenerallyaboveaverage,exceptfortheself-replicationmode, where it performed poorly.They [63] also employed ChatGPT as a network honeypot to defend against attackers. By having ChatGPT mimic Linux, Mac, and Windows terminal commands and providing interfaces for TeamViewer, nmap, and ping, a dynamic environment can be created to adapt to attackers’ operations, and logs can be used to gain insight into their attack methods, tactics, and procedures. The authors demonstrated ten honeypot tasks to illustrate that ChatGPT’s interface not only provides sufficient API memory to execute previous commands without defaulting to repetitive introductory tasks but also offers a responsive welcome program that maintains attackers’ interest in multiple queries. In the field of code generation, there are still several challenges with ChatGPT. Firstly, its application scope is limited as its training data is biased towards programming languages such as Python, C++, and Java, making it potentially unsuitable for some programming languages or coding styles. Secondly, manual optimization is necessary forcodeformatting,asthegeneratedcodemaynotbeperformance-optimizedorfollowbestcodingpractices,requiring manualeditingandoptimization.Lastly,thequalityofthegeneratedcodecannotbeguaranteed,asitheavilyrelieson thequalityofthenaturallanguageinput,whichmaycontainerrors,ambiguities,orinconsistencies,ultimatelyaffecting the accuracy and reliability of the generated code. 2.1.5. Inference Inference refers to the process of drawing new conclusions or information through logical deduction from known facts or information. It is typically based on a series of premises or assumptions, and involves applying logical rules or reasoning methods to arrive at a conclusion. Inference is an important ability in human thinking, and is often used to solve problems, make decisions, analyze and evaluate information, etc. Inference also plays a key role in fields such as science, philosophy, law, etc. There are two types of inference: inductive reasoning, which involves deriving generalrulesorconclusionsfromknownfactsorexperiences,anddeductivereasoning,whichinvolvesderivingspecific conclusions from known premises or assumptions. Whether inductive or deductive, the process of inference requires following strict logical rules to ensure the correctness and reliability of the inference. SomepapersattempttouseChatGPT’sabilityininductivereasoningtocapturethemeaningintextandusedefined metrics to score the text. Michail et al. [65] uses ChatGPT to infer intimacy expressed in tweets. They first input 50 tweets with intimacy markers to ChatGPT, then use inductive reasoning to infer the standards for generating tweets withdifferentlevelsofintimacy,andfinallygeneratetentweetswithintimacyvaluesrangingfrom0to5.Susnjaketal. [86]collectedalargeamountoftextualdatafrompatient-doctordiscussionforums,patienttestimonials,socialmedia platforms, medical journals, and other scientific research publications.

[CHUNK 6]
C++, and Java, making it potentially unsuitable for some programming languages or coding styles. Secondly, manual optimization is necessary forcodeformatting,asthegeneratedcodemaynotbeperformance-optimizedorfollowbestcodingpractices,requiring manualeditingandoptimization.Lastly,thequalityofthegeneratedcodecannotbeguaranteed,asitheavilyrelieson thequalityofthenaturallanguageinput,whichmaycontainerrors,ambiguities,orinconsistencies,ultimatelyaffecting the accuracy and reliability of the generated code. 2.1.5. Inference Inference refers to the process of drawing new conclusions or information through logical deduction from known facts or information. It is typically based on a series of premises or assumptions, and involves applying logical rules or reasoning methods to arrive at a conclusion. Inference is an important ability in human thinking, and is often used to solve problems, make decisions, analyze and evaluate information, etc. Inference also plays a key role in fields such as science, philosophy, law, etc. There are two types of inference: inductive reasoning, which involves deriving generalrulesorconclusionsfromknownfactsorexperiences,anddeductivereasoning,whichinvolvesderivingspecific conclusions from known premises or assumptions. Whether inductive or deductive, the process of inference requires following strict logical rules to ensure the correctness and reliability of the inference. SomepapersattempttouseChatGPT’sabilityininductivereasoningtocapturethemeaningintextandusedefined metrics to score the text. Michail et al. [65] uses ChatGPT to infer intimacy expressed in tweets. They first input 50 tweets with intimacy markers to ChatGPT, then use inductive reasoning to infer the standards for generating tweets withdifferentlevelsofintimacy,andfinallygeneratetentweetswithintimacyvaluesrangingfrom0to5.Susnjaketal. [86]collectedalargeamountoftextualdatafrompatient-doctordiscussionforums,patienttestimonials,socialmedia platforms, medical journals, and other scientific research publications. Using the BERT model, the author inferred emotionvaluesfrom0to1.Theauthorvisualizedtheprocessofhowthepresenceofbiasinthediscoursesurrounding chronicmanifestations ofthe diseaseusing theSHAPtool. Theauthor alsoenvisioned ChatGPTasa replacementfor the BERTmodel forscoring theemotional value oftext. Huanget al.[32] chose12.5% of individualsin thepotential hate dataset as study materials, induced ChatGPT to make classifications based on a prompt, and ChatGPT produced three classifications: unclear, yes, and no. The author assigned a value of 1 to yes, -1 to no, and 0 to unclear, and had ChatGPT score and classify them. ChatGPT was able to correctly classify 80% of implicit hate tweets in the author’s experimental setup, demonstrating ChatGPT’s great potential as a data labeling tool using simple prompts. SomepapershaveevaluatedChatGPT’sreasoningperformance,mainlyindecision-makingandspatialreasoning, and identifying ambiguity. Tang et al. [89] used the independence axiom and the transitivity axiom, as well as other non-VNM related decision-making abilities, by presenting bets conditioned on random events, bets with asymmetric outcomes,decisionsencapsulatingSavage’sSureThingprinciple,andothercomplexbetstructureslikenestedbets,to Yiheng Liu et al.: Preprint submitted to Elsevier Page 9 of 21Summary of ChatGPT-Related Research designexperimentswhereeachexperimentinputashortprompttoChatGPTandevaluatedtheresults.Theconclusion isthatChatGPTexhibitsuncertaintyinthedecision-makingprocess:insomecases,largelanguagemodelscanarriveat thecorrectanswerthroughincorrectreasoning;anditmaymakesuboptimaldecisionsforsimplereasoningproblems. Ortega-Martnetal.[72]hadChatGPTdetectthreedifferentlevelsoflanguageambiguityandevaluateditsperformance. The conclusion is that In semantics, ChatGPT performed perfectly in the detection of ambiguities. Apart from that, it has some bright sports (co-reference resolution) and some weaknesses (puts gender bias over grammar in some non-ambiguous situations). In the generation task ChatGPT did well, but also revealed some of its worse issues: the lack of systematicity. Lastly, it should also be pointed that in most of the cases ChatGPT brilliantly alludes to lack of context as the key factor in disambiguation. 2.1.6. Data or information extraction, transformation, enhancement, processing Data Visualization Natural language interfaces have contributed to generating visualizations directly from natural language, but visualization problems remain challenging due to the ambiguity of natural language.ChatGPT provides a new avenue for the field by converting natural language into visualized code. In terms of data visualization, Noever et al. [69] tested ChatGPT’s basic arithmetic skills by asking questions.On the iris dataset, Titanic survival dataset, Boston housing data, and randomly generated insurance claims dataset, the statisticalanalysisofdataandvisualizationproblemswereconvertedtoprogrammingproblemsusingJupytertoverify ChatGPT’sabilitytogeneratepythoncodetodrawsuitablegraphsandanalyzethedata.TheresultsshowthatChatGPT can access structured and organized datasets to perform the four basic software operations required for databases: create, read, update, and delete, and generate suitable python code to plot graphs for descriptive statistics, variable correlationanalysis,describingtrends,andotherdataanalysisoperations.Maddiganetal.[61]proposedanend-to-end solution for visualizing data in natural language using LLM, which uses an open-source python framework designed togenerateappropriatehintsforselecteddatasetstomakeLLMmoreeffectiveinunderstandingnaturallanguage,and uses internal reasoning capabilities to select the appropriate visualization type to generate the code for visualization. In this paper,the reseachers compare the visualization results of GPT-3, Codex and ChatGPT in the case of nvBench SQLitedatabase[59]andthevisualizationresultsofenergyproductiondatasetinthestudyofADVISorwithNL4DV [53;67].Inadditionto,theyexploretheabilitytoreasonandhypothesizeoftheLLMonmoviedataset[59]whenthe hintsareinsufficientorwrong.ExperimentalresultsshowthatLLMcaneffectivelysupporttheend-to-endgeneration of visualization results from natural language when supported by hints, providing an efficient, reliable and accurate solution to the natural language visualization problem. Information Extraction The goal of information extraction is to extract specific information from natural language text for structured representation, including three important subtasks such as entity relationship extraction, named entity recognition, and event extraction, which have wide applications in business, medical, and other fields. In information extraction, Wei et al. [97] proposed ChatIE, a ChatGPT-based multi-round question-and-answer framework for information extraction. The framework decomposes a complex information extraction (IE) task into several parts, then combines the results of each round into a final structured result. The entity association triple extraction,namedentityrecognition,andeventextractiontaskswereperformedonsixdatasetsNYT11-HRL,DuIE2.0 , conllpp, MSR , DuEE1.0 [87; 50; 96; 49; 51], and ACE05 in both languages, comparing three metrics of precision, recall, and F1 score.These results suggest that on six widely used IE datasets, ChatIE improves performance by an average of 18.98% compared to the original ChatGPT without ChatIE, and outperforms the supervised models FCM andMultiR[21;30]ontheNYT11-HRLdataset.WhiletheoriginalChatGPTcannotsolvecomplexIEproblemswith original task instructions, and with this framework, successfully IE tasks were implemented on six datasets.Gao et al. [19] explored the feasibility and challenges of ChatGPT

[CHUNK 7]
the case of nvBench SQLitedatabase[59]andthevisualizationresultsofenergyproductiondatasetinthestudyofADVISorwithNL4DV [53;67].Inadditionto,theyexploretheabilitytoreasonandhypothesizeoftheLLMonmoviedataset[59]whenthe hintsareinsufficientorwrong.ExperimentalresultsshowthatLLMcaneffectivelysupporttheend-to-endgeneration of visualization results from natural language when supported by hints, providing an efficient, reliable and accurate solution to the natural language visualization problem. Information Extraction The goal of information extraction is to extract specific information from natural language text for structured representation, including three important subtasks such as entity relationship extraction, named entity recognition, and event extraction, which have wide applications in business, medical, and other fields. In information extraction, Wei et al. [97] proposed ChatIE, a ChatGPT-based multi-round question-and-answer framework for information extraction. The framework decomposes a complex information extraction (IE) task into several parts, then combines the results of each round into a final structured result. The entity association triple extraction,namedentityrecognition,andeventextractiontaskswereperformedonsixdatasetsNYT11-HRL,DuIE2.0 , conllpp, MSR , DuEE1.0 [87; 50; 96; 49; 51], and ACE05 in both languages, comparing three metrics of precision, recall, and F1 score.These results suggest that on six widely used IE datasets, ChatIE improves performance by an average of 18.98% compared to the original ChatGPT without ChatIE, and outperforms the supervised models FCM andMultiR[21;30]ontheNYT11-HRLdataset.WhiletheoriginalChatGPTcannotsolvecomplexIEproblemswith original task instructions, and with this framework, successfully IE tasks were implemented on six datasets.Gao et al. [19] explored the feasibility and challenges of ChatGPT for event extraction on the ACE2005 corpus, evaluating the performance of ChatGPT in long-tail and complex scenarios (texts containing multiple events) and comparing it with two task-specific models, Text2Event and EEQA [57; 14].Then,they explored the impact of different cues on performance of ChatGPT. The results show that the average performance of ChatGPT in long-tail and complex scenariosisonly51.04%ofthatoftask-specificmodelssuchasEEQA.Continuousrefinementofcuesdoesnotleadto consistentperformanceimprovements,andChatGPTishighlysensitivetodifferentcuestyles.Tangetal.[88]proposed a new training paradigm that incorporates appropriate cues to guide ChatGPT to generate a variety of examples with Yiheng Liu et al.: Preprint submitted to Elsevier Page 10 of 21Summary of ChatGPT-Related Research different sentence structures and language patterns and eliminate the resulting low-quality or duplicate samples for downstream tasks. Although compared to a soft model for a specific healthcare task, ChatGPT underperforms in Named Entity Recognition (NER) and Relationship Extraction (RE) tasks , in the Gene Association Database (GAD) Release; EU-ADR corpus for the RE task , the innovative training framework was able to train local models, with F1 scores improving from 23.37% to 63.99% for the named entity recognition task and from 75%, while alleviating privacy concerns and time-consuming data collection and annotation problems.He et al. [28] proposed a contextual learning framework ICL- D3IE. this framework introduces formatted presentation, continuously iterates to update and improve the presentation, and then combines ChatGPT for text information extraction. In the paper, ICL-D3IE iscomparedwithexistingpre-trainedmodelssuchasLiLT,BROS(in-distribution(ID)settingandout-of-distribution (OOD)setting)ondatasets(FUNSD,CORD,andSROIE[35;75;34]).TheseresultsshowthattheICL-D3IEmethod inalldatasetsandsettingsexceptfortheIDsettingonCORDaresuperiortoothermethods,withICL-D3IE(GPT-3) F1 scores reaching 90.32% on FUNSD and97.88% on SROIE; in the out-of-distribution (OOD) setting, ICL-D3IE performsmuchbetterthanpreviouspre-trainedmethodsonalldatasets.Polaketal.[76]proposedChatExtractmethod - consisting of a set of engineering prompts applied to a conversational LLM - for automatic data extraction. During experiment,theyextractedalargenumberofsentencesfromhundredsofpapersandrandomlyselected100sentences containing data and 100 sentences without data as test data. The results show that the accuracy and recall of LLM exceeded 90% and may be comparable to human accuracy in many cases; in addition to this, the experiments were conductedundertheconditionofremovingfollow-uppromptsandnotkeepingtheconversationcomparedtoprevious experiments, respectively. The accuracy of deleting follow-up questions dropped to 80.2% and the recall rate dropped to88.0%.Removingtheconversationalaspectandrelatedinformationretentionrecallandaccuracydroppedto90.0% and 56.6%, respectively, demonstrating the effect of information retention combined with purposeful redundancy on LLM information extraction performance. Quality Assessment Fortranslationquality,textgenerationquality,manualassessmentisusuallyeffectivebutsuffersfromsubjectivity andtime-consuming,etc.ItwasfoundthroughexplorationthatChatGPThasalsoachievedsignificantperformancein automatic quality assessment. In terms of quality assessment, Kocmi et al. [41] proposed a GPT-based translation quality assessment metric, GEMBA, which evaluates the translation of each fragment individually and then averages all the obtained scores to obtain a final system-level score. In the MQM2022 test set (English-German, English-Russian, and Chinese-English) [15], a scoring task was performed with a classification task to compare the accuracy [42] and kendall tau scores [16] of seven GPT models under four cue templates.The results showed that GEMBA had the highest system-level accuracy of 88.0% compared to more than 10 automatic metrics such as BLEU, and among the seven GPT models, ChatGPTaccuracyisabove80%,inadditionto,thebestperformancecanbeobtainedintheleastconstrainedtemplate, demonstrating the potential of LLM for translation quality assessment tasks, but the evaluation is only applicable at the system level and needs further improvement.Wang et al. [93] used ChatGPT as a natural language generation (NLG) evaluator to study the correlation with human judgment. On three datasets covering different NLG tasks, task- and aspect-specific cues were designed to guide ChatGPT for NLG evaluation in CNN/DM [29], OpenMEVA- ROC,andBAGELforsummary,storygeneration,anddata-to-textscoring,respectively.Then,theycomputeSpearman coefficients[105],Pearsoncorrelationcoefficients[66].Kendall’sTauscore[38]toassessthecorrelationwithhuman evaluations.TheresultsshowthatChatGPTishighlycorrelatedwithhumanjudgmentsinallaspects,withcorrelation coefficients of 0.4 or more in all categories, showing its potential as an NLG indicator. Data Augmentation Innaturallanguageprocessing,textdataaugmentationisaneffectivemeasuretoalleviatetheproblemoflowdata quantity and low quality training data, and ChatGPT has shown great potential in this regard. In terms of data augmentation, Dai et al. [13] proposed a ChatGPT-based text data augmentation method that reformulateseachsentenceinthetrainingsampleintomultipleconceptuallysimilarbutsemanticallydifferentsamples forclassificationtasksdownstreamoftheBertmodel.OntexttranscriptionsandPubMed20kdatasetscontainingmore than8hoursofaudiodataofcommonmedicalsymptomdescriptions,experimentswereconductedtocomparecosine similarityandTransRatemetricswithmultipledataenhancementmethods[33].Thispapershowsthatcomparedwith existing data enhancement methods, the proposed ChatAug method shows a double-digit improvement in sentence Yiheng Liu et al.: Preprint submitted to Elsevier Page 11 of 21Summary of ChatGPT-Related Research classificationaccuracyandgeneratesmorediverseaugmentedsampleswhilemaintainingitsaccuracy,buttheoriginal model is not fine-tuned

[CHUNK 8]
accuracy [42] and kendall tau scores [16] of seven GPT models under four cue templates.The results showed that GEMBA had the highest system-level accuracy of 88.0% compared to more than 10 automatic metrics such as BLEU, and among the seven GPT models, ChatGPTaccuracyisabove80%,inadditionto,thebestperformancecanbeobtainedintheleastconstrainedtemplate, demonstrating the potential of LLM for translation quality assessment tasks, but the evaluation is only applicable at the system level and needs further improvement.Wang et al. [93] used ChatGPT as a natural language generation (NLG) evaluator to study the correlation with human judgment. On three datasets covering different NLG tasks, task- and aspect-specific cues were designed to guide ChatGPT for NLG evaluation in CNN/DM [29], OpenMEVA- ROC,andBAGELforsummary,storygeneration,anddata-to-textscoring,respectively.Then,theycomputeSpearman coefficients[105],Pearsoncorrelationcoefficients[66].Kendall’sTauscore[38]toassessthecorrelationwithhuman evaluations.TheresultsshowthatChatGPTishighlycorrelatedwithhumanjudgmentsinallaspects,withcorrelation coefficients of 0.4 or more in all categories, showing its potential as an NLG indicator. Data Augmentation Innaturallanguageprocessing,textdataaugmentationisaneffectivemeasuretoalleviatetheproblemoflowdata quantity and low quality training data, and ChatGPT has shown great potential in this regard. In terms of data augmentation, Dai et al. [13] proposed a ChatGPT-based text data augmentation method that reformulateseachsentenceinthetrainingsampleintomultipleconceptuallysimilarbutsemanticallydifferentsamples forclassificationtasksdownstreamoftheBertmodel.OntexttranscriptionsandPubMed20kdatasetscontainingmore than8hoursofaudiodataofcommonmedicalsymptomdescriptions,experimentswereconductedtocomparecosine similarityandTransRatemetricswithmultipledataenhancementmethods[33].Thispapershowsthatcomparedwith existing data enhancement methods, the proposed ChatAug method shows a double-digit improvement in sentence Yiheng Liu et al.: Preprint submitted to Elsevier Page 11 of 21Summary of ChatGPT-Related Research classificationaccuracyandgeneratesmorediverseaugmentedsampleswhilemaintainingitsaccuracy,buttheoriginal model is not fine-tuned in the paper and suffers from a lack of domain knowledge, which may produce incorrect augmented data. Multimodal fusion ChatGPT can currently only process natural language directly, but with a cross-modal encoder, it can combine naturallanguagewithcross-modalprocessingtoprovidesolutionsforintelligenttransportation,healthcare,andother fields. In terms of multimodal data processing, Wu et al. [101] constructed a framework that Visual ChatGPT integrates with different Visual Foundation Models (VFMs) and then combines a series of hints to input visual information to ChatGPT to solve visual problems.The paper shows examples of visual tasks such as removing or replacing certain objectsfromimages,interconversionbetweenimagesandtext,demonstratingtheVisualChatGPThasgreatpotential and capability for different tasks.But there are issues during the task that requires a large number of hints to convert VFMs to language, invoke multiple VFMs to solve complex problems leading to limited real-time capability, and security and privacy issues. Zheng et al. [109] showed a text mining example of LLM for extracting self-driving car crash data from California crash news, analyzing a failure report example, and generating a crash report example based on keywords; introduced a use case concept of a smartphone-based framework for automatic LLM failure report generation, which absorbs multiple data sources captured by cell phone sensors and then transfers the data toa languagespacefortext mining,inferenceand generation,andfurther outputsthekeyinformation neededtoform a comprehensive fault report, demonstrating the potential of LLM for a variety of transportation tasks. Nowadays, ChatGPT shows a wide range of applications in data visualization, information extraction, data enhancement, quality assessment, and multimodal data processing.But there are also issues on how to further utilize hints to effectively interact with ChatGPT, lack of ability to process and analyze data from devices such as sensors, and data privacy and security. Cueing Techniques Cue engineering provides important support for effective dialogue with large language models.White et al. [99] proposed a framework for cueing models applicable to different domains. This framework structures cues to interact with LLMs by providing specific rules and guidelines. Also, this paper presents a catalog of cueing patterns that have been applied to LLM interactions, as well as specific examples with and without cues. The advantages of the combinability of prompting patterns are demonstrated, allowing users to interact with LLM more effectively, but patterns for reusable solutions and new ways to use LLM need to be continuously explored. 2.1.7. Human-ChatGPT Collaboration Collaboration between humans and machines is a process where humans and machines work together to achieve a common goal. In such collaboration, humans provide domain expertise, creativity, and decision-making abilities, while machines provide automation, scalability, and computing power. ChatGPT is an advanced natural language processing model that can understand and generate human-like language, thereby reducing communication costs. Its abilitytoprocessandgeneratenaturallanguagemakesitanidealpartnerforhumancollaboration.ChatGPTcanoffer relevant suggestions, complete tasks based on human input, and enhance human productivity and creativity. It can learnfromhumanfeedbackandadapttonewtasksanddomains,furtherimprovingitsperformanceinhuman-machine collaboration. ChatGPT’s capability to comprehend natural language and produce appropriate responses makes it a valuable tool for various collaboration applications, as demonstrated by several studies in the literature we have gathered. Ahmad et al. [1] proposed a method for human-machine collaboration using ChatGPT to create software archi- tecture. This method transforms software stories (created by software architects based on application scenarios) into feasible software architecture diagrams through continuous interaction between the software architect and ChatGPT. During the evaluation stage, ChatGPT uses the Software Architecture Analysis Method (SAAM) to evaluate each componentinthesoftwarearchitectureandgenerateevaluationreports.Thismethodefficientlyutilizestheknowledge and supervision of the architect with the capabilities of ChatGPT to collaboratively build software-intensive systems and services. Lanzi et al. [47] proposed a collaborative design framework that combines interactive evolution and ChatGPT to simulate typical human design processes. Humans collaborate with large language models (such as ChatGPT) to recombine and transform ideas, and use genetic algorithms to iterate through complex

[CHUNK 9]
and decision-making abilities, while machines provide automation, scalability, and computing power. ChatGPT is an advanced natural language processing model that can understand and generate human-like language, thereby reducing communication costs. Its abilitytoprocessandgeneratenaturallanguagemakesitanidealpartnerforhumancollaboration.ChatGPTcanoffer relevant suggestions, complete tasks based on human input, and enhance human productivity and creativity. It can learnfromhumanfeedbackandadapttonewtasksanddomains,furtherimprovingitsperformanceinhuman-machine collaboration. ChatGPT’s capability to comprehend natural language and produce appropriate responses makes it a valuable tool for various collaboration applications, as demonstrated by several studies in the literature we have gathered. Ahmad et al. [1] proposed a method for human-machine collaboration using ChatGPT to create software archi- tecture. This method transforms software stories (created by software architects based on application scenarios) into feasible software architecture diagrams through continuous interaction between the software architect and ChatGPT. During the evaluation stage, ChatGPT uses the Software Architecture Analysis Method (SAAM) to evaluate each componentinthesoftwarearchitectureandgenerateevaluationreports.Thismethodefficientlyutilizestheknowledge and supervision of the architect with the capabilities of ChatGPT to collaboratively build software-intensive systems and services. Lanzi et al. [47] proposed a collaborative design framework that combines interactive evolution and ChatGPT to simulate typical human design processes. Humans collaborate with large language models (such as ChatGPT) to recombine and transform ideas, and use genetic algorithms to iterate through complex creative tasks. Yiheng Liu et al.: Preprint submitted to Elsevier Page 12 of 21Summary of ChatGPT-Related Research The results of three game design tasks showed that the framework received positive feedback from game designers. The framework has good reusability and can be applied to any design task that can be described in free text form. In the future, ChatGPT’s ability to understand nonverbal cues such as tone of voice and body language can be enhanced, enabling it to better understand human thoughts and interact with people more effectively. 2.1.8. ChatGPT Integration Integrationreferstocombiningdifferentsystemsorsoftwarecomponentstoachieveacommongoal.ChatGPTcan be integrated as a part of a whole or act as an integration tool to enable seamless communication between different systems.Itsnaturallanguageprocessingabilitymakesiteasierfornon-technicaluserstointeractwithsystems,reducing the need for specialized knowledge or training. Some studies in the literature we collected have already demonstrated this. Treude et al. [90] integrated ChatGPT into the prototype of "GPTCOMCARE" to address programming query problems. This integration allowed for the generation of multiple source code solutions for the same query, which increased the efficiency of software development. The results of their study demonstrated the effectiveness of using ChatGPT to improve the quality and diversity of code solutions, ultimately reducing the amount of time and effort required for software development. Wang et al. [94] proposed the chatCAD method, which utilizes large language models (LLMs) such as ChatGPT to enhance the output of multiple CAD networks for medical images, including diagnosis, lesion segmentation, and report generation networks. The method generates suggestions in the form of a chat dialogue. The authors tested the effectiveness of the method on a randomly selected set of 300 cases from the MIMIC-CXR dataset, which included 50 cases each of cardiomegaly, edema, consolidation, atelectasis, pleural effusion, and no findings. Compared to CvT2DistilGPT2 and R2GenCMN, chatCAD showed significant advantages in RC and F1, while only performing weaker than R2GenCMN in PR. IntegratingChatGPTintoapplicationswillstillpresentchallenges.Firstly,ChatGPT’sperformancemaybeaffected by language barriers or differences in terminology between different systems. Additionally, ChatGPT’s responses are notalwaysdeterministic,whichposesachallengewhenintegratingwithsystemsthatrequirepreciseandreproducible results. Finally, the processing time of ChatGPT is slow for integration tasks involving time-sensitive data such as traffic, which is a limitation in time-critical environments. 2.1.9. Medical Applications ChatGPT offers promising applications in medical field, revolutionizing healthcare practices. Its natural language processingcapabilitiesenable interactiveassistanceforradiologists,aidingin imageannotation,lesiondetection,and classification.ChatGPT’sextensiveknowledgebasefacilitatesreal-timefeedback,context-specificrecommendations, and streamlined report generation. By integrating ChatGPT into workflows, healthcare professionals benefit from enhanced efficiency and precision in clinical decision-making, fostering accessible and collaborative healthcare solutions. For example: ChatCAD [94] integrates large language models (LLMs) into computer-aided diagnosis (CAD) networks for medical imaging. It has shown promising results in improving diagnosis, lesion segmentation, and report generation, three key aspects of CAD networks. This integration represents a notable effort in combining large language models with medical imaging techniques. Hu et al. [31] conducted a comprehensive review of language models in the context of medical imaging and highlightedthepotentialadvantagesofChatGPTinenhancingclinicalworkflowefficiency,reducingdiagnosticerrors, andsupportinghealthcareprofessionals.Theirworkaimstobridgethegapbetweenlargelanguagemodelsandmedical imaging, paving the way for new ideas and innovations in this research domain. Ma et al. [60] proposed ImpressionGPT, a novel approach that harnesses the powerful in-context learning capabilities of ChatGPT. They achieve this by creating dynamic contexts using domain-specific and individualized data.Thedynamicpromptmethodenablesthemodeltolearncontextualknowledgefromsemanticallysimilarexamples in existing data and iteratively optimize the results, aiding radiologists in composing the "impression" section based on the "findings" section. The results demonstrate state-of-the-art performance on both the MIMIC-CXR and OpenI datasets, without the need for additional training data or fine-tuning of the LLMs. AD-AutoGPT[12],anintegrationofAutoGPT[22],leveragesthepowerofChatGPTinanautomatedprocessing pipeline that can assist users in accomplishing nearly any given task. With AD-AutoGPT, users can autonomously generate data collection, processing, and analysis pipelines based on their text prompts. Through AD-AutoGPT, detailed trend analysis, mapping of topic distances, and identification of significant terms related to Alzheimer’s Yiheng Liu et al.: Preprint

[CHUNK 10]
into computer-aided diagnosis (CAD) networks for medical imaging. It has shown promising results in improving diagnosis, lesion segmentation, and report generation, three key aspects of CAD networks. This integration represents a notable effort in combining large language models with medical imaging techniques. Hu et al. [31] conducted a comprehensive review of language models in the context of medical imaging and highlightedthepotentialadvantagesofChatGPTinenhancingclinicalworkflowefficiency,reducingdiagnosticerrors, andsupportinghealthcareprofessionals.Theirworkaimstobridgethegapbetweenlargelanguagemodelsandmedical imaging, paving the way for new ideas and innovations in this research domain. Ma et al. [60] proposed ImpressionGPT, a novel approach that harnesses the powerful in-context learning capabilities of ChatGPT. They achieve this by creating dynamic contexts using domain-specific and individualized data.Thedynamicpromptmethodenablesthemodeltolearncontextualknowledgefromsemanticallysimilarexamples in existing data and iteratively optimize the results, aiding radiologists in composing the "impression" section based on the "findings" section. The results demonstrate state-of-the-art performance on both the MIMIC-CXR and OpenI datasets, without the need for additional training data or fine-tuning of the LLMs. AD-AutoGPT[12],anintegrationofAutoGPT[22],leveragesthepowerofChatGPTinanautomatedprocessing pipeline that can assist users in accomplishing nearly any given task. With AD-AutoGPT, users can autonomously generate data collection, processing, and analysis pipelines based on their text prompts. Through AD-AutoGPT, detailed trend analysis, mapping of topic distances, and identification of significant terms related to Alzheimer’s Yiheng Liu et al.: Preprint submitted to Elsevier Page 13 of 21Summary of ChatGPT-Related Research disease (AD) have been achieved from four new sources specifically relevant to AD. This significantly contributes to the existing knowledge base and facilitates a nuanced understanding of discourse surrounding diseases in the field of public health. It lays the groundwork for future research in AI-assisted public health studies. Patient privacy protection has always been a significant concern in the healthcare field. DeID-GPT [55] aims to explore the potential of ChatGPT in the de-identification and anonymization of medical reports. Experimental results demonstrate that ChatGPT exhibit promising capabilities in medical data de-identification compared to other LLMs. Despite notable efforts, the integration of large language models and medical imaging still presents several challenges.Firstly,theintricateandtechnicalnatureofmedicalimagingdata,whichencompassesdetailedanatomical structures and subtle abnormalities, may not be effectively conveyed or comprehended through the text-based chat interfaceoflargelanguagemodels.Secondly,ChatGPTlacksthespecializedmedicalknowledgeandtrainingnecessary for precise interpretation and analysis of medical images, potentially leading to dangerous misunderstandings or inaccurate diagnoses [52]. It is imperative to establish various machine learning models to detect samples generated by both humans and ChatGPT, in order to prevent false medical information produced by ChatGPT from causing misjudgmentsindiseaseprogression,delayingtreatmentprocesses,ornegativelyimpactingpatients’livesandhealth. Lastly,thelegalandethicalaspectsassociatedwithdeployingartificialintelligencemodelslikeChatGPTinamedical context, such as patient privacy and liability concerns, must be thoughtfully addressed and aligned with regulatory standards. While ChatGPT is powerful, it is not easily applicable in clinical settings. Compliance with HIPAA regulations,privacyissues,andthenecessityforIRBapprovalposesignificantobstacles[55],primarilybecausethese modelsrequireuploadingpatientdatatoexternalhostingplatforms.Onepossiblesolutiontothisproblemistoaddress itthroughlocalizeddeploymentoflanguagemodels,suchasRadiology-GPT[56].ThefutureapplicationofchatGPT in the field of medical imaging will necessitate ongoing efforts from all stakeholders. 2.2. AI Ethics Since the advent of ChatGPT, this powerful natural language processing model has not only brought great conveniencetopeoplebutalsotriggeredmorecrisis-awarethinking.Someresearchershavestartedtohypothesizeand study the potential negative impacts of ChatGPT. This proactive research provides good proposals for standardized construction to address future AI abuse issues. Regarding the possibility of ChatGPT being used for plagiarism and cheating, Zhou et al. [111] reflected on the current state of development of artificial intelligence like ChatGPT. As ChatGPT becomes increasingly easy to obtain and scalable in text generation, there is a high likelihood that these technologies will be used for plagiarism, includingscientificliteratureandnewssources,posingagreatthreattothecredibilityofvariousformsofnewsmedia and academic articles. Some scholars are concerned that the end of paper as a meaningful evaluation tool may be approaching [100; 104], as ChatGPT can easily generate persuasive paragraphs, chapters, and papers on any given topic. Additionally, it will exacerbate plagiarism issues in many fields such as education, medicine, and law [48], and maybeusedforcheatinginacademicexams[85].Definitionalrecognitiontechnologyisarelativelyeffectivemethod fordetectingplagiarism,andthedefinitionaltypologyproposedin[111]canalleviatepeople’sconcernsbybeingused to construct new datasets. Susnjak [85] proposed a solution to the possibility of large language models like ChatGPT beingusedforexamcheating:guidingChatGPTtogeneratesomecriticalthinkingproblemsthroughquestioning,then providing answers and critically evaluating them. Analysis of ChatGPT shows that it exhibits critical thinking, can generate highly realistic text in terms of accuracy, relevance, depth, breadth, logic, persuasiveness, and originality. Therefore, educators must be aware of the possibility of ChatGPT being used for exam cheating and take measures to combat cheating behavior to ensure the fairness of online exams. Regarding the evaluation of ChatGPT’s own political and ethical tendencies, Hartmann et al. [27] used Wahl-O- Mat, one of the most commonly used voting advice applications in the world, to show ChatGPT political statements from different parties, forcing it to make choices of agree, disagree, or neutral. The results indicated that ChatGPT has a pro-environment, left-wing liberal ideology, which was also confirmed in the nation-state agnostic political compasstest.Anotherstudy(referencedas[45])examinedChatGPT’smoralstandardsbyrepeatedlyaskingitdifferent versionsofthetrolleyproblem,andfoundthatChatGPTgaveanswerswithdifferentmoralorientations,lackingafirm moralstance.AsubsequenttestalsofoundthatChatGPT’slackofconsistencycouldaffectpeople’smoraljudgments. Additionally,Borjietal.[7]demonstratedChatGPT’sinconsistencyinreasoning,factualerrors,mathematics,coding, and bias across eleven related aspects. These findings highlight ChatGPT’s inherent traits and limitations, and people should be aware of their potential impact when seeking advice from ChatGPT. Zhuo et al. [112] comprehensively analyzed the moral hazard, bias, reliability, robustness, and toxicity of ChatGPT from four perspectives. The results Yiheng Liu et al.: Preprint submitted to Elsevier Page 14 of 21Summary of ChatGPT-Related Research foundthatChatGPTmayperformslightlybetterthanthecurrentSOTAlanguagemodel,buthassomeshortcomingsin allfouraspects.Theauthorslookaheadtotheethicalchallengesofdevelopingadvancedlanguagemodelsandsuggest directions

[CHUNK 11]
ChatGPT beingusedforexamcheating:guidingChatGPTtogeneratesomecriticalthinkingproblemsthroughquestioning,then providing answers and critically evaluating them. Analysis of ChatGPT shows that it exhibits critical thinking, can generate highly realistic text in terms of accuracy, relevance, depth, breadth, logic, persuasiveness, and originality. Therefore, educators must be aware of the possibility of ChatGPT being used for exam cheating and take measures to combat cheating behavior to ensure the fairness of online exams. Regarding the evaluation of ChatGPT’s own political and ethical tendencies, Hartmann et al. [27] used Wahl-O- Mat, one of the most commonly used voting advice applications in the world, to show ChatGPT political statements from different parties, forcing it to make choices of agree, disagree, or neutral. The results indicated that ChatGPT has a pro-environment, left-wing liberal ideology, which was also confirmed in the nation-state agnostic political compasstest.Anotherstudy(referencedas[45])examinedChatGPT’smoralstandardsbyrepeatedlyaskingitdifferent versionsofthetrolleyproblem,andfoundthatChatGPTgaveanswerswithdifferentmoralorientations,lackingafirm moralstance.AsubsequenttestalsofoundthatChatGPT’slackofconsistencycouldaffectpeople’smoraljudgments. Additionally,Borjietal.[7]demonstratedChatGPT’sinconsistencyinreasoning,factualerrors,mathematics,coding, and bias across eleven related aspects. These findings highlight ChatGPT’s inherent traits and limitations, and people should be aware of their potential impact when seeking advice from ChatGPT. Zhuo et al. [112] comprehensively analyzed the moral hazard, bias, reliability, robustness, and toxicity of ChatGPT from four perspectives. The results Yiheng Liu et al.: Preprint submitted to Elsevier Page 14 of 21Summary of ChatGPT-Related Research foundthatChatGPTmayperformslightlybetterthanthecurrentSOTAlanguagemodel,buthassomeshortcomingsin allfouraspects.Theauthorslookaheadtotheethicalchallengesofdevelopingadvancedlanguagemodelsandsuggest directions and strategies for designing ethical language models. Regarding relevant policies and regulations, Hacker et al. [25] discussed the nature and rules of large generative AImodels,includingChatGPT,whicharerapidlychangingthewaywecommunicate,explain,andcreate.Theauthor suggestedthatdifferentstakeholdersinthevaluechainshouldtakeregulatoryresponsibilityanddeployfourstrategies totailormorecomprehensivelawsforthebenefitofsociety.Anotherstudy(referencedas[24])criticizedtheEuropean Commission’sproposalonAIresponsibilityandsuggestedrevisingtheproposedAIresponsibilityframeworktoensure effectivecompensationwhilepromotinginnovation,legalcertainty,andsustainableAIregulation.Apolicyframework was proposed (referenced as [40]) to customize LLMs, such as ChatGPT, in a socially acceptable and safe manner, emphasizing the need to align large language models (LLMs) with human preferences. The political and ethical tendencies of ChatGPT could influence users’ behavior and decision-making to some extent. However, some studies have conducted in-depth research on the use of norms and limitations, which could enable humans to use ChatGPT more reasonably and safely. 3. Evaluation 3.1. Comparison of ChatGPT with existing popular models WeusepubliclyavailabledatasetstocomprehensivelyevaluatethestrengthsandlimitationsofChatGPT.Reference [3] evaluates the technical performance of ChatGPT in multitask, multilingual, and multimodal aspects based on 23 standard public datasets and newly designed multimodal datasets, including eight different common natural language processing application tasks. The experimental results show that, in terms of multitasking, ChatGPT outperforms variousstate-of-the-artzero-shotlearninglargelanguagemodelsinmosttasks,andevenoutperformsfine-tunedtask- specific models in some individual tasks. In terms of multilingualism, we found that ChatGPT cannot be applied to low-resourcelanguagesbecauseitcannotunderstandthelanguageandgeneratetranslationsforthatlanguage.Interms of multimodality, ChatGPT’s ability is still basic compared to specialized language-visual models. Intermsofstability,reference[43]concludesthatChatGPT’sperformanceisalwayslowerthanSOTA,thecurrent state-of-the-art model, in almost all tasks. This means that as a general model, ChatGPT has never reached the level of the best existing models. Experimental data shows that the average quality of the SOTA model is 73.7%, while the average quality of the ChatGPT model is only 56.5%. At the same time, ChatGPT’s stability is poor: the standard deviation of its performance is 23.3%, while the SOTA model’s standard deviation is only 16.7%. This non- deterministic behavior exhibited by ChatGPT could be a serious drawback in some problems. Similarly,Qinetal.[78]conductedacomprehensiveevaluationofwhetherChatGPTisaqualifiedgeneralnatural languageprocessingtasksolver.TheexperimentanalyzedChatGPT’szero-shotlearningabilitybasedon20commonly usedpublicdatasetscovering7representativetaskcategories.Below,wewillanalyzeChatGPT’sperformanceoneach task: Intermsofreasoningtasks,ChatGPTperformsaverageonmathematicalsymbol,commonsensecausal,andlogical reasoningtasks,butperformswellinarithmeticreasoning[78].Thatistosay,ChatGPT’sabilitiesvaryamongdifferent types of reasoning tasks. In terms of logical reasoning, ChatGPT’s deductive and abductive reasoning are superior to inductive reasoning, while in other reasoning tasks, such as analogy, causal and commonsense reasoning, ChatGPT performs well [3]. In terms of sentiment analysis task, ChatGPT performs similarly to GPT-3.5 and bert-style models [78; 110]. However,accordingtoliterature[43],ChatGPThaslossesnotexceeding25%onmosttasks,exceptforthreerelatively subjectiveemotionperceptiontaskswhereitperformspoorly.Ifweremovethesetaskstocalculatetheaveragequality of the two models, we find that the SOTA method has an average quality of 80%, while the ChatGPT method has an averagequalityof69.7%.Thatistosay,ChatGPTperformswellonalltasksexceptforemotion-relatedtasks,andcan handle most of the problems we consider. However, overall, its performance is lower than the SOTA model based on experimental data, but the difference between the two is not very large. In other tasks, according to literature [78], ChatGPT performs well in natural language inference, i.e., the task of inferringsentencerelationships,anditsperformanceonthistaskissignificantlybetterthanallbert-stylemodels[110]. However, while ChatGPT performs well on inference tasks, it may produce some self-contradictory or unreasonable responses, which is its potential limitation. In question-answering, dialogue, and summarization tasks, ChatGPT performs better than the GPT-3.5 model [78], especially in the question-answering task, where its performance is Yiheng Liu et al.: Preprint submitted to Elsevier Page 15 of 21Summary of ChatGPT-Related Research comparabletobert-stylemodels[110].Therefore,wehavedemonstratedthatChatGPTisaqualifiedgeneral-purpose model. However,ChatGPTalsohaslimitationsinmanyaspects.Firstly,itlackstheabilitytohandlenon-textualsemantic reasoning tasks such as mathematical, temporal, and spatial reasoning, and it performs poorly in multi-hop reasoning [3]. Secondly, ChatGPT is not good at solving named entity recognition tasks [78]. Furthermore, ChatGPT performs poorly in handling tasks involving negative connotations and neutral similarity [110]. Finally, these conclusions indicatethat,likeotherlargepre-trainedlanguagemodels,ChatGPThaslimitationsincompletingcomplexreasoning tasks. In summary, ChatGPT’s zero-shot performance is comparable to fine-tuned bert and GPT-3.5 models, and with thehelpofadvancedpromptingstrategies,ChatGPTcandemonstratebettercomprehensionabilities.However,itstill cannot outperform the current SOTA models. 3.2. Feedback from ChatGPT users In response to feedback from ChatGPT users, Haque et al. [26] conducted a mixed-methods study using 10,732 early ChatGPT user tweets. The authors extracted Twitter data using Python and Twitter API and constructed the ChatGPTTweet dataset, which contains 18k tweets. For each tweet, the authors collected information on text content, user location, occupation, verification status,

[CHUNK 12]
natural language inference, i.e., the task of inferringsentencerelationships,anditsperformanceonthistaskissignificantlybetterthanallbert-stylemodels[110]. However, while ChatGPT performs well on inference tasks, it may produce some self-contradictory or unreasonable responses, which is its potential limitation. In question-answering, dialogue, and summarization tasks, ChatGPT performs better than the GPT-3.5 model [78], especially in the question-answering task, where its performance is Yiheng Liu et al.: Preprint submitted to Elsevier Page 15 of 21Summary of ChatGPT-Related Research comparabletobert-stylemodels[110].Therefore,wehavedemonstratedthatChatGPTisaqualifiedgeneral-purpose model. However,ChatGPTalsohaslimitationsinmanyaspects.Firstly,itlackstheabilitytohandlenon-textualsemantic reasoning tasks such as mathematical, temporal, and spatial reasoning, and it performs poorly in multi-hop reasoning [3]. Secondly, ChatGPT is not good at solving named entity recognition tasks [78]. Furthermore, ChatGPT performs poorly in handling tasks involving negative connotations and neutral similarity [110]. Finally, these conclusions indicatethat,likeotherlargepre-trainedlanguagemodels,ChatGPThaslimitationsincompletingcomplexreasoning tasks. In summary, ChatGPT’s zero-shot performance is comparable to fine-tuned bert and GPT-3.5 models, and with thehelpofadvancedpromptingstrategies,ChatGPTcandemonstratebettercomprehensionabilities.However,itstill cannot outperform the current SOTA models. 3.2. Feedback from ChatGPT users In response to feedback from ChatGPT users, Haque et al. [26] conducted a mixed-methods study using 10,732 early ChatGPT user tweets. The authors extracted Twitter data using Python and Twitter API and constructed the ChatGPTTweet dataset, which contains 18k tweets. For each tweet, the authors collected information on text content, user location, occupation, verification status, date of publication, and tags. Based on this dataset, the authors studied the characteristics of early ChatGPT users, discussion topics related to ChatGPT on Twitter, and the sentiment of Twitter users toward ChatGPT. For RQ1, the authors found that early ChatGPT users had a diverse and wide range of occupational backgrounds and geographical locations. For RQ2, the authors identified nine topics related toChatGPT,includingitsimpactonsoftwaredevelopment,entertainmentandcreativity,naturallanguageprocessing, education,chatbotintelligence,businessdevelopment,searchengines,question-answeringtests,andfuturecareersand opportunities.ForRQ3,mostearlyusersexpressedpositivesentimenttowardtopicssuchassoftwaredevelopmentand creativity, while only a few expressed concern about the potential misuse of ChatGPT. 3.3. Adverse effects of ChatGPT on users Regarding the negative effects of ChatGPT on users, Luan et al. [58] studied the psychological principles of ChatGPT, delved into the factors that attract users’ attention, and revealed the impact of these factors on future learning. In the post-pandemic era, teachers and students are both facing uncertainty in the teaching process and job pressures. Under these common constraints of education and employment, educators and students must re-evaluate current educational methods and outcomes, as well as students’ future career development. Through question-and- answerexchangeswithChatGPT,peoplecaneasilyobtainappropriatesolutionsorkeyinformation,therebyenhancing theirmotivation,eliminatinganxietyinlearning,improvinginterest,andachievingpsychologicalsatisfaction.Subhash et al. [84] explored whether large language models have the ability to reverse user preferences. With the development of pre-trained large language models, people are increasingly concerned about the ability of these models to influence,persuade,andpotentiallymanipulateuserpreferencesinextremecases.Therefore,theliterature[84]roughly qualitatively analyzed that adversarial behavior does lead to potential changes in user preferences and behaviors in dialogue systems. If we want to further quantitatively analyze the ability of large language models in this regard, additional statistical summary techniques need to be used for future research. 4. Discussion 4.1. Limitations DespitetheremarkablecapabilitiesofChatGPT,itstillfacescertainlimitations.Someoftheselimitationsinclude: Outdated Knowledge Thecurrentmodelsaretrainedonhistoricaldata(upto2021),therebylackingreal-timecomprehensionofcurrent affairs. This is a critical concern in today’s information-explosion era, as the reliability of prior knowledge bases progressively diminishes, potentially yielding inaccurate responses, especially in rapidly evolving domains such as jurisprudence and technology. Additionally, these models are incapable of fact-checking while the training data is composedofcontentfromvarioussources,someofwhichmaybeunreliable,whichmayresultinseeminglyplausible yet nonsensical responses. Yiheng Liu et al.: Preprint submitted to Elsevier Page 16 of 21Summary of ChatGPT-Related Research Insufficient Understanding While these models can interpret the majority of inquiries and contextual situations, they occasionally encounter comprehension biases when addressing ambiguous or contextually complex queries. Furthermore, in certain spe- cialized fields, the abundance of unique abbreviation exacerbates the models’ understanding challenges, resulting in incorrect and vacuous responses. Energy Consumption Throughoutthetrainingandinferencestages,theselarge-scalemodelsrequiresignificantcomputationalresources and electrical power, resulting in elevated energy consumption and significant carbon emissions. Consequently, this restricts their deployment and practical applications. Malicious Usage Despite OpenAI implementing a series of restrictions to mitigate model toxicity, instances of users evading these constraints through meticulously designed prompts have emerged, inducing the model to produce unhealthy content or even using it for illicit commercial purposes. Bias and Discrimination Due to the influence of pre-training data, the models exhibit biases in political, ideological, and other areas. The application of LLMs in public domains, such as education and publicity, should be approached with extreme caution. Privacy and Data Security Concurrentwiththeexpansionofusers,protectinguserprivacyanddatasecuritybecomesincreasinglyimportant. In fact, ChatGPT was banned in Italy in early April due to privacy concerns. This is particularly relevant given the models’ extensive collection of personal information and preferences during interactions, and as future multimodal models, such as GPT-4, may frequently require users to upload private photos. 4.2. Future Directions Inforthcomingresearch,thedevelopmentofmodelsbasedonChatGPTmayfocusonaddressingtheselimitations to enhance their practical applications. Primarily,researchersshouldcontinuetoworkonrefiningmodeltrainingmethodologieswhilefilteringpre-training data to minimize the presence of misleading information in the model’s knowledge base, thereby obtaining accurate responses. Concurrently, it is crucial to emphasize training approaches that economize computational resources, thereby mitigating costs and broadening potential application scenarios. Moreover, the advancements in context-awareness and disambiguation technologies are anticipated to facilitate enhancedcomprehensionofcomplexqueriesbymodels,improvingtheaccuracy,relevance,andcontext-awarenessof AI-generated content. Integrating real-time data streams can also keep these models in sync with current events and trends, enabling them

[CHUNK 13]
to mitigate model toxicity, instances of users evading these constraints through meticulously designed prompts have emerged, inducing the model to produce unhealthy content or even using it for illicit commercial purposes. Bias and Discrimination Due to the influence of pre-training data, the models exhibit biases in political, ideological, and other areas. The application of LLMs in public domains, such as education and publicity, should be approached with extreme caution. Privacy and Data Security Concurrentwiththeexpansionofusers,protectinguserprivacyanddatasecuritybecomesincreasinglyimportant. In fact, ChatGPT was banned in Italy in early April due to privacy concerns. This is particularly relevant given the models’ extensive collection of personal information and preferences during interactions, and as future multimodal models, such as GPT-4, may frequently require users to upload private photos. 4.2. Future Directions Inforthcomingresearch,thedevelopmentofmodelsbasedonChatGPTmayfocusonaddressingtheselimitations to enhance their practical applications. Primarily,researchersshouldcontinuetoworkonrefiningmodeltrainingmethodologieswhilefilteringpre-training data to minimize the presence of misleading information in the model’s knowledge base, thereby obtaining accurate responses. Concurrently, it is crucial to emphasize training approaches that economize computational resources, thereby mitigating costs and broadening potential application scenarios. Moreover, the advancements in context-awareness and disambiguation technologies are anticipated to facilitate enhancedcomprehensionofcomplexqueriesbymodels,improvingtheaccuracy,relevance,andcontext-awarenessof AI-generated content. Integrating real-time data streams can also keep these models in sync with current events and trends, enabling them to provide up-to-date information such as live traffic, weather, and stock updates. Additionally, developers should engage in interdisciplinary collaboration with specialists from diverse domains, including policy-making, jurisprudence, and sociology, with the objective of formulating standard and ethical frameworks for LLM development, deployment, and utilization, thereby alleviating potential harmful consequences. Intermsofpublicawarenessandeducation,mandatoryawarenesstrainingshouldbeimplementedpriortolarge-scale public deployment and application to increase public awareness of LLM capabilities and limitations while promoting responsible and informed utilization, especially in industries such as K-12 education and journalism. Furthermore, ChatGPT still lacks specific domain knowledge and may encounter potential data security issues, especiallyinthemedicalfield.Indomainswhereerrortoleranceislowanddataprivacyandsecurityarecrucial,such as medical applications [55], localized training and deployment of LLMs should be considered [56]. Customizing training for specific LLMs based on domain-specific data should also be taken into account. Finally,theinfluenceofChatGPTshouldnotbelimitedtojusttheNLPfield.Theyalsoshowpromisingprospects in the areas of computer vision, brain-inspired AI, and robotics. These models exhibit a capacity for learning and comprehensioncomparablewithhuman-levelintelligence,positioningthemasapivotalcomponentinthedevelopment ofartificialgeneralintelligence(AGI)[108].Theirabilitytofacilitateseamlessinteractionsbetweenhumansandrobots paves the way for the execution of more complex tasks. The remarkable capacity of zero-shot in-context learning of Yiheng Liu et al.: Preprint submitted to Elsevier Page 17 of 21Summary of ChatGPT-Related Research these models enables quick adaptation to new tasks without the requirement for labeled data for fine-tuning, which is a critical challenge in fields like medical informatics[55] and robotics[54] where the availability of labeled data is commonly limited or non-existent. 5. Conclusion This review paper provides a comprehensive survey of ChatGPT, highlighting their potential applications and significant contributions to the field of natural language processing. The findings of this study reveal that the interest in these models is growing rapidly, and they have shown considerable potential for application across a wide range of domains. One key factor contributing to the success of ChatGPT is their ability to perform large-scale pre-training, whichcapturesknowledgefromthevastexpanseoftheinternet,allowingthemodelstolearnfromamassiveamount ofdata.TheintegrationofReinforcementLearningfromHumanFeedback(RLHF)hasfurtherenhancedthemodel’s adaptability and performance, making it highly efficient in processing natural language. In addition, RLHF aligns languagemodelswithhumanpreferences&valuesandempowertextgenerationwiththenaturalnessofhumanstyle. This study has also identified several potential ethical concerns related to the development and use of ChatGPT. For instance,thereareconcernsaboutthegenerationofbiasedorharmfulcontent,privacyviolations,andthepotentialfor misuse of the technology. It is crucial to address these concerns and ensure that ChatGPT is developed and used in a responsibleandethicalmanner.Furthermore,theresultsofthisstudydemonstratethatthereissignificantpotentialfor ChatGPTtobeappliedinarangeofdomains,includingeducation,medical,history,mathematics,physics,andmore. These models can facilitate tasks such as generating summaries, answering questions, and providing personalized recommendationstousers.Overall,theinsightspresentedinthisreviewpapercanserveasausefulguideforresearchers and practitioners looking to advance the field of natural language processing. Future research in this field should focus on addressing ethical concerns, exploring new applications, and ensuring the responsible use of ChatGPT. The potential of these models to revolutionize natural language processing is enormous, and we look forward to seeing more developments in this field. Acknowledgement This work was supported by the National Natural Science Foundation of China (No. 61976131). References [1] Ahmad,A.,Waseem,M.,Liang,P.,Fehmideh,M.,Aktar,M.S.,Mikkonen,T.:Towardshuman-botcollaborativesoftwarearchitectingwith chatgpt. arXiv preprint arXiv:2302.14600 (2023) [2] Amin, M.M., Cambria, E., Schuller, B.W.: Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt. arXiv preprint arXiv:2303.03186 (2023) [3] Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., et al.: A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023 (2023) [4] Basic,Z.,Banovac,A.,Kruzic,I.,Jerkovic,I.:Betterbyyou,betterthanme,chatgpt3aswritingassistanceinstudentsessays.arXivpreprint arXiv:2302.04536 (2023) [5] Belouadi, J., Eger, S.: Bygpt5: End-to-end style-conditioned poetry generation with token-free language models. arXiv preprint arXiv:2212.10474 (2022) [6] Blanco-Gonzalez,A.,Cabezon,A.,Seco-Gonzalez,A.,Conde-Torres,D.,Antelo-Riveiro,P.,Pineiro,A.,Garcia-Fandino,R.:Theroleofai in drug discovery: Challenges, opportunities, and strategies. arXiv preprint arXiv:2212.08104 (2022) [7] Borji, A.: A categorical archive of chatgpt failures. arXiv preprint arXiv:2302.03494 (2023) [8] Brown,T.,Mann,B.,Ryder,N.,Subbiah,M.,Kaplan,J.D.,Dhariwal,P.,Neelakantan,A.,Shyam,P.,Sastry,G.,Askell,A.,etal.:Language models are few-shot learners. Advances in neural information processing systems 33, 1877–1901 (2020) [9] Chen, N., Wang, Y., Jiang, H., Cai, D., Chen, Z., Li, J.: What would harry say? building dialogue agents for characters in a story. arXiv preprint arXiv:2211.06869 (2022) [10] Chen, Y., Eger, S.:

[CHUNK 14]
language processing is enormous, and we look forward to seeing more developments in this field. Acknowledgement This work was supported by the National Natural Science Foundation of China (No. 61976131). References [1] Ahmad,A.,Waseem,M.,Liang,P.,Fehmideh,M.,Aktar,M.S.,Mikkonen,T.:Towardshuman-botcollaborativesoftwarearchitectingwith chatgpt. arXiv preprint arXiv:2302.14600 (2023) [2] Amin, M.M., Cambria, E., Schuller, B.W.: Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt. arXiv preprint arXiv:2303.03186 (2023) [3] Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., et al.: A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023 (2023) [4] Basic,Z.,Banovac,A.,Kruzic,I.,Jerkovic,I.:Betterbyyou,betterthanme,chatgpt3aswritingassistanceinstudentsessays.arXivpreprint arXiv:2302.04536 (2023) [5] Belouadi, J., Eger, S.: Bygpt5: End-to-end style-conditioned poetry generation with token-free language models. arXiv preprint arXiv:2212.10474 (2022) [6] Blanco-Gonzalez,A.,Cabezon,A.,Seco-Gonzalez,A.,Conde-Torres,D.,Antelo-Riveiro,P.,Pineiro,A.,Garcia-Fandino,R.:Theroleofai in drug discovery: Challenges, opportunities, and strategies. arXiv preprint arXiv:2212.08104 (2022) [7] Borji, A.: A categorical archive of chatgpt failures. arXiv preprint arXiv:2302.03494 (2023) [8] Brown,T.,Mann,B.,Ryder,N.,Subbiah,M.,Kaplan,J.D.,Dhariwal,P.,Neelakantan,A.,Shyam,P.,Sastry,G.,Askell,A.,etal.:Language models are few-shot learners. Advances in neural information processing systems 33, 1877–1901 (2020) [9] Chen, N., Wang, Y., Jiang, H., Cai, D., Chen, Z., Li, J.: What would harry say? building dialogue agents for characters in a story. arXiv preprint arXiv:2211.06869 (2022) [10] Chen, Y., Eger, S.: Transformers go for the lols: Generating (humourous) titles from scientific abstracts end-to-end. arXiv preprint arXiv:2212.10522 (2022) [11] Christiano,P.F.,Leike,J.,Brown,T.,Martic,M.,Legg,S.,Amodei,D.:Deepreinforcementlearningfromhumanpreferences.Advancesin neural information processing systems 30(2017) [12] Dai, H., Li, Y., Liu, Z., Zhao, L., Wu, Z., Song, S., Shen, Y., Zhu, D., Li, X., Li, S., et al.: Ad-autogpt: An autonomous gpt for alzheimer’s disease infodemiology. arXiv preprint arXiv:2306.10095 (2023) [13] Dai, H., Liu, Z., Liao, W., Huang, X., Wu, Z., Zhao, L., Liu, W., Liu, N., Li, S., Zhu, D., et al.: Chataug: Leveraging chatgpt for text data augmentation. arXiv preprint arXiv:2302.13007 (2023) [14] Du, X., Cardie, C.: Event extraction by answering (almost) natural questions. arXiv preprint arXiv:2004.13625 (2020) Yiheng Liu et al.: Preprint submitted to Elsevier Page 18 of 21Summary of ChatGPT-Related Research [15] Freitag,M.,Rei,R.,Mathur,N.,Lo,C.k.,Stewart,C.,Avramidis,E.,Kocmi,T.,Foster,G.,Lavie,A.,Martins,A.F.:Resultsofwmt22metrics shared task: Stop using bleu–neural metrics are better and more robust. In: Proceedings of the Seventh Conference on Machine Translation (WMT). pp. 46–68 (2022) [16] Freitag,M.,Rei,R.,Mathur,N.,Lo,C.k.,Stewart,C.,Avramidis,E.,Kocmi,T.,Foster,G.,Lavie,A.,Martins,A.F.:Resultsofwmt22metrics shared task: Stop using bleu–neural metrics are better and more robust. In: Proceedings of the Seventh Conference on Machine Translation (WMT). pp. 46–68 (2022) [17] Frieder,S.,Pinchetti,L.,Griffiths,R.R.,Salvatori,T.,Lukasiewicz,T.,Petersen,P.C.,Chevalier,A.,Berner,J.:Mathematicalcapabilitiesof chatgpt. arXiv preprint arXiv:2301.13867 (2023) [18] Fu,Q.,Teng,Z.,Georgaklis,M.,White,J.,Schmidt,D.C.:Nl2cmd:Anupdatedworkflowfornaturallanguagetobashcommandstranslation. arXiv preprint arXiv:2302.07845 (2023) [19] Gao, J., Zhao, H., Yu, C., Xu, R.: Exploring the feasibility of chatgpt for event extraction. arXiv preprint arXiv:2303.03836 (2023) [20] Glymour, C., Zhang, K., Spirtes, P.: Review of causal discovery methods based on graphical models. Frontiers in Genetics (2019) [21] Gormley, M.R., Yu, M., Dredze, M.: Improved relation extraction with feature-rich compositional embedding models. arXiv preprint arXiv:1505.02419 (2015) [22] Gravitas, S.: Auto-gpt: An autonomous gpt-4 experiment (2023) [23] Guo, S., Wang, Y., Li, S., Saeed, N.: Semantic communications with ordered importance using chatgpt. arXiv preprint arXiv:2302.07142 (2023) [24] Hacker,P.:Theeuropeanailiabilitydirectives–critiqueofahalf-heartedapproachandlessonsforthefuture.arXivpreprintarXiv:2211.13960 (2022) [25] Hacker, P., Engel, A., Mauer, M.: Regulating chatgpt and other large generative ai models. arXiv preprint arXiv:2302.02337 (2023) [26] Haque, M.U., Dharmadasa, I., Sworna, Z.T., Rajapakse, R.N., Ahmad, H.: " i think this is the most disruptive technology": Exploring sentiments of chatgpt early adopters using twitter data. arXiv preprint arXiv:2212.05856 (2022) [27] Hartmann, J., Schwenzow, J., Witte, M.: The political ideology of conversational ai: Converging evidence on chatgpt’s pro-environmental, left-libertarian orientation. arXiv preprint arXiv:2301.01768 (2023) [28] He,J.,Wang,L.,Hu,Y.,Liu,N.,Liu,H.,Xu,X.,Shen,H.T.:Icl-d3ie:In-contextlearningwithdiversedemonstrationsupdatingfordocument information extraction. arXiv preprint arXiv:2303.05063 (2023) [29] Hermann,K.M.,Kocisky,T.,Grefenstette,E.,Espeholt,L.,Kay,W.,Suleyman,M.,Blunsom,P.:Teachingmachinestoreadandcomprehend. Advances in neural information processing systems 28(2015) [30] Hoffmann,R.,Zhang,C.,Ling,X.,Zettlemoyer,L.,Weld,D.S.:Knowledge-basedweaksupervisionforinformationextractionofoverlapping relations. In: Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies. pp. 541–550 (2011) [31] Hu, M., Pan, S., Li, Y., Yang, X.: Advancing medical imaging with language models: A journey from n-grams to chatgpt. arXiv preprint arXiv:2304.04920 (2023) [32] Huang,F.,Kwak,H.,An,J.:Ischatgptbetterthanhumanannotators?potentialandlimitationsofchatgptinexplainingimplicithatespeech. arXiv preprint arXiv:2302.07736 (2023) [33] Huang, L.K., Huang, J., Rong, Y., Yang, Q., Wei, Y.: Frustratingly easy transferability estimation pp. 9201–9225 (2022) [34] Huang, Z., Chen, K., He, J., Bai, X., Karatzas, D., Lu, S., Jawahar, C.: Icdar2019 competition on scanned receipt ocr and information extraction. In: 2019 International Conference on Document Analysis and Recognition (ICDAR). pp. 1516–1520. IEEE (2019) [35] Jaume,G.,Ekenel,H.K.,Thiran,J.P.:Funsd:Adatasetforformunderstandinginnoisyscanneddocuments.In:2019InternationalConference on Document Analysis and Recognition Workshops (ICDARW). vol. 2, pp. 1–6. IEEE (2019) [36] Jeblick,K.,Schachtner,B.,Dexl,J.,Mittermeier,A.,Stüber,A.T.,Topalis,J.,Weber,T.,Wesp,P.,Sabel,B.,Ricke,J.,etal.:Chatgptmakes medicine easy to swallow: An exploratory case study on simplified radiology reports. arXiv preprint arXiv:2212.14882 (2022) [37] Jiao, W., ZhaopengTu, W.J.t.X.: Is chatgpt a good translator? yes with gpt-4 as the engine [38] Kendall, M.G.: A new measure of rank correlation. Biometrika 30(1/2), 81–93 (1938) [39] Khalil, M., Er, E.: Will chatgpt get you caught? rethinking of plagiarism detection. arXiv preprint arXiv:2302.04335 (2023) [40] Kirk, H.R., Vidgen, B., Röttger, P., Hale, S.A.: Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback. arXiv preprint arXiv:2303.05453 (2023) [41] Kocmi, T., Federmann, C.: Large

[CHUNK 15]
Li, Y., Yang, X.: Advancing medical imaging with language models: A journey from n-grams to chatgpt. arXiv preprint arXiv:2304.04920 (2023) [32] Huang,F.,Kwak,H.,An,J.:Ischatgptbetterthanhumanannotators?potentialandlimitationsofchatgptinexplainingimplicithatespeech. arXiv preprint arXiv:2302.07736 (2023) [33] Huang, L.K., Huang, J., Rong, Y., Yang, Q., Wei, Y.: Frustratingly easy transferability estimation pp. 9201–9225 (2022) [34] Huang, Z., Chen, K., He, J., Bai, X., Karatzas, D., Lu, S., Jawahar, C.: Icdar2019 competition on scanned receipt ocr and information extraction. In: 2019 International Conference on Document Analysis and Recognition (ICDAR). pp. 1516–1520. IEEE (2019) [35] Jaume,G.,Ekenel,H.K.,Thiran,J.P.:Funsd:Adatasetforformunderstandinginnoisyscanneddocuments.In:2019InternationalConference on Document Analysis and Recognition Workshops (ICDARW). vol. 2, pp. 1–6. IEEE (2019) [36] Jeblick,K.,Schachtner,B.,Dexl,J.,Mittermeier,A.,Stüber,A.T.,Topalis,J.,Weber,T.,Wesp,P.,Sabel,B.,Ricke,J.,etal.:Chatgptmakes medicine easy to swallow: An exploratory case study on simplified radiology reports. arXiv preprint arXiv:2212.14882 (2022) [37] Jiao, W., ZhaopengTu, W.J.t.X.: Is chatgpt a good translator? yes with gpt-4 as the engine [38] Kendall, M.G.: A new measure of rank correlation. Biometrika 30(1/2), 81–93 (1938) [39] Khalil, M., Er, E.: Will chatgpt get you caught? rethinking of plagiarism detection. arXiv preprint arXiv:2302.04335 (2023) [40] Kirk, H.R., Vidgen, B., Röttger, P., Hale, S.A.: Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback. arXiv preprint arXiv:2303.05453 (2023) [41] Kocmi, T., Federmann, C.: Large language models are state-of-the-art evaluators of translation quality. arXiv preprint arXiv:2302.14520 (2023) [42] Kocmi, T., Federmann, C., Grundkiewicz, R., Junczys-Dowmunt, M., Matsushita, H., Menezes, A.: To ship or not to ship: An extensive evaluation of automatic metrics for machine translation. arXiv preprint arXiv:2107.10821 (2021) [43] Kocoń,J.,Cichecki,I.,Kaszyca,O.,Kochanek,M.,Szydło,D.,Baran,J.,Bielaniewicz,J.,Gruza,M.,Janz,A.,Kanclerz,K.,etal.:Chatgpt: Jack of all trades, master of none. arXiv preprint arXiv:2302.10724 (2023) [44] Kortemeyer, G.: Could an artificial-intelligence agent pass an introductory physics course? arXiv preprint arXiv:2301.12127 (2023) [45] Krügel, S., Ostermaier, A., Uhl, M.: The moral authority of chatgpt. arXiv preprint arXiv:2301.07098 (2023) [46] Kuzman, T., Mozetic, I., Ljubešic, N.: Chatgpt: Beginning of an end of manual linguistic data annotation? use case of automatic genre identification. arXiv e-prints pp. arXiv–2303 (2023) [47] Lanzi,P.L.,Loiacono,D.:Chatgptandotherlargelanguagemodelsasevolutionaryenginesforonlineinteractivecollaborativegamedesign. arXiv preprint arXiv:2303.02155 (2023) [48] Lehnert, K.: Ai insights into theoretical physics and the swampland program: A journey through the cosmos with chatgpt. arXiv preprint arXiv:2301.08155 (2023) [49] Levow,G.A.:Thethirdinternationalchineselanguageprocessingbakeoff:Wordsegmentationandnamedentityrecognition.In:Proceedings of the Fifth SIGHAN workshop on Chinese language processing. pp. 108–117 (2006) Yiheng Liu et al.: Preprint submitted to Elsevier Page 19 of 21Summary of ChatGPT-Related Research [50] Li, S., He, W., Shi, Y., Jiang, W., Liang, H., Jiang, Y., Zhang, Y., Lyu, Y., Zhu, Y.: Duie: A large-scale chinese dataset for information extraction. In: Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019, Dunhuang, China, October 9–14, 2019, Proceedings, Part II 8. pp. 791–800. Springer (2019) [51] Li, X., Li, F., Pan, L., Chen, Y., Peng, W., Wang, Q., Lyu, Y., Zhu, Y.: Duee: a large-scale dataset for chinese event extraction in real-world scenarios. In: Natural Language Processing and Chinese Computing: 9th CCF International Conference, NLPCC 2020, Zhengzhou, China, October 14–18, 2020, Proceedings, Part II 9. pp. 534–545. Springer (2020) [52] Liao,W.,Liu,Z.,Dai,H.,Xu,S.,Wu,Z.,Zhang,Y.,Huang,X.,Zhu,D.,Cai,H.,Liu,T.,etal.:Differentiatechatgpt-generatedandhuman- written medical texts. arXiv preprint arXiv:2304.11567 (2023) [53] Liu,C.,Han,Y.,Jiang,R.,Yuan,X.:Advisor:Automaticvisualizationanswerfornatural-languagequestionontabulardata.In:2021IEEE 14th Pacific Visualization Symposium (PacificVis). pp. 11–20. IEEE (2021) [54] Liu, D., Chen, Y., Wu, Z.: Digital twin (dt)-cyclegan: Enabling zero-shot sim-to-real transfer of visual grasping models. IEEE Robotics and Automation Letters (2023) [55] Liu,Z.,Yu,X.,Zhang,L.,Wu,Z.,Cao,C.,Dai,H.,Zhao,L.,Liu,W.,Shen,D.,Li,Q.,etal.:Deid-gpt:Zero-shotmedicaltextde-identification by gpt-4. arXiv preprint arXiv:2303.11032 (2023) [56] Liu, Z., Zhong, A., Li, Y., Yang, L., Ju, C., Wu, Z., Ma, C., Shu, P., Chen, C., Kim, S., et al.: Radiology-gpt: A large language model for radiology. arXiv preprint arXiv:2306.08666 (2023) [57] Lu, Y., Lin, H., Xu, J., Han, X., Tang, J., Li, A., Sun, L., Liao, M., Chen, S.: Text2event: Controllable sequence-to-structure generation for end-to-end event extraction. arXiv preprint arXiv:2106.09232 (2021) [58] Luan, L., Lin, X., Li, W.: Exploring the cognitive dynamics of artificial intelligence in the post-covid-19 and learning 3.0 era: A case study of chatgpt. arXiv preprint arXiv:2302.04818 (2023) [59] Luo, Y., Tang, J., Li, G.: nvbench: A large-scale synthesized dataset for cross-domain natural language to visualization task. arXiv preprint arXiv:2112.12926 (2021) [60] Ma, C., Wu, Z., Wang, J., Xu, S., Wei, Y., Liu, Z., Guo, L., Cai, X., Zhang, S., Zhang, T., et al.: Impressiongpt: an iterative optimizing framework for radiology report summarization with chatgpt. arXiv preprint arXiv:2304.08448 (2023) [61] Maddigan, P., Susnjak, T.: Chat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language models. arXiv preprint arXiv:2302.02094 (2023) [62] McKee, F., Noever, D.: Chatbots in a botnet world. arXiv preprint arXiv:2212.11126 (2022) [63] McKee, F., Noever, D.: Chatbots in a honeypot world. arXiv preprint arXiv:2301.03771 (2023) [64] Megahed, F.M., Chen, Y.J., Ferris, J.A., Knoth, S., Jones-Farmer, L.A.: How generative ai models such as chatgpt can be (mis) used in spc practice, education, and research? an exploratory study. arXiv preprint arXiv:2302.10916 (2023) [65] Michail,A.,Konstantinou,S.,Clematide,S.:Uzh_clypatsemeval-2023task9:Head-firstfine-tuningandchatgptdatagenerationforcross- lingual learning in tweet intimacy prediction. arXiv preprint arXiv:2303.01194 (2023) [66] Mukaka, M.M.: A guide to appropriate use of correlation coefficient

[CHUNK 16]
Luan, L., Lin, X., Li, W.: Exploring the cognitive dynamics of artificial intelligence in the post-covid-19 and learning 3.0 era: A case study of chatgpt. arXiv preprint arXiv:2302.04818 (2023) [59] Luo, Y., Tang, J., Li, G.: nvbench: A large-scale synthesized dataset for cross-domain natural language to visualization task. arXiv preprint arXiv:2112.12926 (2021) [60] Ma, C., Wu, Z., Wang, J., Xu, S., Wei, Y., Liu, Z., Guo, L., Cai, X., Zhang, S., Zhang, T., et al.: Impressiongpt: an iterative optimizing framework for radiology report summarization with chatgpt. arXiv preprint arXiv:2304.08448 (2023) [61] Maddigan, P., Susnjak, T.: Chat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language models. arXiv preprint arXiv:2302.02094 (2023) [62] McKee, F., Noever, D.: Chatbots in a botnet world. arXiv preprint arXiv:2212.11126 (2022) [63] McKee, F., Noever, D.: Chatbots in a honeypot world. arXiv preprint arXiv:2301.03771 (2023) [64] Megahed, F.M., Chen, Y.J., Ferris, J.A., Knoth, S., Jones-Farmer, L.A.: How generative ai models such as chatgpt can be (mis) used in spc practice, education, and research? an exploratory study. arXiv preprint arXiv:2302.10916 (2023) [65] Michail,A.,Konstantinou,S.,Clematide,S.:Uzh_clypatsemeval-2023task9:Head-firstfine-tuningandchatgptdatagenerationforcross- lingual learning in tweet intimacy prediction. arXiv preprint arXiv:2303.01194 (2023) [66] Mukaka, M.M.: A guide to appropriate use of correlation coefficient in medical research. Malawi medical journal 24(3), 69–71 (2012) [67] Narechania,A.,Srinivasan,A.,Stasko,J.:Nl4dv:Atoolkitforgeneratinganalyticspecificationsfordatavisualizationfromnaturallanguage queries. IEEE Transactions on Visualization and Computer Graphics 27(2), 369–379 (2020) [68] Noever, D., Ciolino, M.: The turing deception. arXiv preprint arXiv:2212.06721 (2022) [69] Noever, D., McKee, F.: Numeracy from literacy: Data science as an emergent skill from large language models. arXiv preprint arXiv:2301.13382 (2023) [70] Nov, O., Singh, N., Mann, D.M.: Putting chatgpt’s medical advice to the (turing) test. medRxiv (2023) [71] OpenAI: Gpt-4 technical report (2023) [72] Ortega-Martín, M., García-Sierra, Ó., Ardoiz, A., Álvarez, J., Armenteros, J.C., Alonso, A.: Linguistic ambiguity analysis in chatgpt. arXiv preprint arXiv:2302.06426 (2023) [73] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al.: Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 (2022) [74] Pardos, Z.A., Bhandari, S.: Learning gain differences between chatgpt and human tutor generated algebra hints. arXiv preprint arXiv:2302.06871 (2023) [75] Park, S., Shin, S., Lee, B., Lee, J., Surh, J., Seo, M., Lee, H.: Cord: a consolidated receipt dataset for post-ocr parsing. In: Workshop on Document Intelligence at NeurIPS 2019 (2019) [76] Polak, M.P., Morgan, D.: Extracting accurate materials data from research papers with conversational language models and prompt engineering–example of chatgpt. arXiv preprint arXiv:2303.05352 (2023) [77] Prieto, S.A., Mengiste, E.T., de Soto, B.G.: Investigating the use of ChatGPT for the scheduling of construction projects. Buildings 13(4), 857 (mar 2023). https://doi.org/10.3390/buildings13040857, https://doi.org/10.3390%2Fbuildings13040857 [78] Qin,C.,Zhang,A.,Zhang,Z.,Chen,J.,Yasunaga,M.,Yang,D.:Ischatgptageneral-purposenaturallanguageprocessingtasksolver?arXiv preprint arXiv:2302.06476 (2023) [79] Radford,A.,Narasimhan,K.,Salimans,T.,Sutskever,I.,etal.:Improvinglanguageunderstandingbygenerativepre-training.OpenAI(2018) [80] Radford,A.,Wu,J.,Amodei,D.,Amodei,D.,Clark,J.,Brundage,M.,Sutskever,I.:Betterlanguagemodelsandtheirimplications.OpenAI Blog https://openai. com/blog/better-language-models 1(2) (2019) [81] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.: Language models are unsupervised multitask learners. OpenAI blog1(8), 9 (2019) [82] Shakarian,P.,Koyyalamudi,A.,Ngu,N.,Mareedu,L.:Anindependentevaluationofchatgptonmathematicalwordproblems(mwp).arXiv preprint arXiv:2302.13814 (2023) [83] Sobania, D., Briesch, M., Hanna, C., Petke, J.: An analysis of the automatic bug fixing performance of chatgpt. arXiv preprint arXiv:2301.08653 (2023) Yiheng Liu et al.: Preprint submitted to Elsevier Page 20 of 21Summary of ChatGPT-Related Research [84] Subhash, V.: Can large language models change user preference adversarially? arXiv preprint arXiv:2302.10291 (2023) [85] Susnjak, T.: Chatgpt: The end of online exam integrity? arXiv preprint arXiv:2212.09292 (2022) [86] Susnjak,T.:Applyingbertandchatgptforsentimentanalysisoflymediseaseinscientificliterature.arXivpreprintarXiv:2302.06474(2023) [87] Takanobu, R., Zhang, T., Liu, J., Huang, M.: A hierarchical framework for relation extraction with reinforcement learning. In: Proceedings of the AAAI conference on artificial intelligence. vol. 33, pp. 7072–7079 (2019) [88] Tang, R., Han, X., Jiang, X., Hu, X.: Does synthetic data generation of llms help clinical text mining? arXiv preprint arXiv:2303.04360 (2023) [89] Tang,Z.,Kejriwal,M.:Apilotevaluationofchatgptanddall-e2ondecisionmakingandspatialreasoning.arXivpreprintarXiv:2302.09068 (2023) [90] Treude, C.: Navigating complexity in software engineering: A prototype for comparing gpt-n solutions. arXiv preprint arXiv:2301.12169 (2023) [91] Tu, R., Ma, C., Zhang, C.: Causal-discovery performance of chatgpt in the context of neuropathic pain diagnosis. arXiv preprint arXiv:2301.13819 (2023) [92] Wang, J., Liang, Y., Meng, F., Li, Z., Qu, J., Zhou, J.: Cross-lingual summarization via chatgpt. arXiv preprint arXiv:2302.14229 (2023) [93] Wang, J., Liang, Y., Meng, F., Shi, H., Li, Z., Xu, J., Qu, J., Zhou, J.: Is chatgpt a good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048 (2023) [94] Wang,S.,Zhao,Z.,Ouyang,X.,Wang,Q.,Shen,D.:Chatcad:Interactivecomputer-aideddiagnosisonmedicalimageusinglargelanguage models. arXiv preprint arXiv:2302.07257 (2023) [95] Wang,S.,Scells,H.,Koopman,B.,Zuccon,G.:Canchatgptwriteagoodbooleanqueryforsystematicreviewliteraturesearch?arXivpreprint arXiv:2302.03495 (2023) [96] Wang, Z., Shang, J., Liu, L., Lu, L., Liu, J., Han, J.: Crossweigh: Training named entity tagger from imperfect annotations. arXiv preprint arXiv:1909.01441 (2019) [97] Wei, X., Cui, X., Cheng, N., Wang, X., Zhang, X., Huang, S., Xie, P., Xu, J., Chen, Y., Zhang, M., et al.: Zero-shot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205 (2023) [98] West, C.G.: Ai and the fci: Can chatgpt project an understanding of introductory physics? arXiv preprint arXiv:2303.01067 (2023) [99] White,J.,Fu,Q.,Hays,S.,Sandborn,M.,Olea,C.,Gilbert,H.,Elnashar,A.,Spencer-Smith,J.,Schmidt,D.C.:Apromptpatterncatalogto enhance prompt engineering with chatgpt. arXiv preprint

[CHUNK 17]
help clinical text mining? arXiv preprint arXiv:2303.04360 (2023) [89] Tang,Z.,Kejriwal,M.:Apilotevaluationofchatgptanddall-e2ondecisionmakingandspatialreasoning.arXivpreprintarXiv:2302.09068 (2023) [90] Treude, C.: Navigating complexity in software engineering: A prototype for comparing gpt-n solutions. arXiv preprint arXiv:2301.12169 (2023) [91] Tu, R., Ma, C., Zhang, C.: Causal-discovery performance of chatgpt in the context of neuropathic pain diagnosis. arXiv preprint arXiv:2301.13819 (2023) [92] Wang, J., Liang, Y., Meng, F., Li, Z., Qu, J., Zhou, J.: Cross-lingual summarization via chatgpt. arXiv preprint arXiv:2302.14229 (2023) [93] Wang, J., Liang, Y., Meng, F., Shi, H., Li, Z., Xu, J., Qu, J., Zhou, J.: Is chatgpt a good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048 (2023) [94] Wang,S.,Zhao,Z.,Ouyang,X.,Wang,Q.,Shen,D.:Chatcad:Interactivecomputer-aideddiagnosisonmedicalimageusinglargelanguage models. arXiv preprint arXiv:2302.07257 (2023) [95] Wang,S.,Scells,H.,Koopman,B.,Zuccon,G.:Canchatgptwriteagoodbooleanqueryforsystematicreviewliteraturesearch?arXivpreprint arXiv:2302.03495 (2023) [96] Wang, Z., Shang, J., Liu, L., Lu, L., Liu, J., Han, J.: Crossweigh: Training named entity tagger from imperfect annotations. arXiv preprint arXiv:1909.01441 (2019) [97] Wei, X., Cui, X., Cheng, N., Wang, X., Zhang, X., Huang, S., Xie, P., Xu, J., Chen, Y., Zhang, M., et al.: Zero-shot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205 (2023) [98] West, C.G.: Ai and the fci: Can chatgpt project an understanding of introductory physics? arXiv preprint arXiv:2303.01067 (2023) [99] White,J.,Fu,Q.,Hays,S.,Sandborn,M.,Olea,C.,Gilbert,H.,Elnashar,A.,Spencer-Smith,J.,Schmidt,D.C.:Apromptpatterncatalogto enhance prompt engineering with chatgpt. arXiv preprint arXiv:2302.11382 (2023) [100] de Winter, J.: Can chatgpt pass high school exams on english language comprehension? (2023) [101] Wu, C., Yin, S., Qi, W., Wang, X., Tang, Z., Duan, N.: Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671 (2023) [102] Xia, C.S., Zhang, L.: Conversational automated program repair. arXiv preprint arXiv:2301.13246 (2023) [103] Yang,X.,Li,Y.,Zhang,X.,Chen,H.,Cheng,W.:Exploringthelimitsofchatgptforqueryoraspect-basedtextsummarization.arXivpreprint arXiv:2302.08081 (2023) [104] Yeadon,W.,Inyang,O.O.,Mizouri,A.,Peach,A.,Testrow,C.:Thedeathoftheshort-formphysicsessayinthecomingairevolution.arXiv preprint arXiv:2212.11661 (2022) [105] Zar, J.H.: Spearman rank correlation. Encyclopedia of biostatistics 7(2005) [106] Zhang, B., Ding, D., Jing, L.: How would stance detection techniques evolve after the launch of chatgpt? arXiv preprint arXiv:2212.14548 (2022) [107] Zhang, X., Chowdhury, R.R., Hong, D., Gupta, R.K., Shang, J.: Modeling label semantics improves activity recognition. arXiv preprint arXiv:2301.03462 (2023) [108] Zhao, L., Zhang, L., Wu, Z., Chen, Y., Dai, H., Yu, X., Liu, Z., Zhang, T., Hu, X., Jiang, X., et al.: When brain-inspired ai meets agi. arXiv preprint arXiv:2303.15935 (2023) [109] Zheng,O.,Abdel-Aty,M.,Wang,D.,Wang,Z.,Ding,S.:Chatgptisonthehorizon:Couldalargelanguagemodelbeallweneedforintelligent transportation? arXiv preprint arXiv:2303.05382 (2023) [110] Zhong,Q.,Ding,L.,Liu,J.,Du,B.,Tao,D.:Canchatgptunderstandtoo?acomparativestudyonchatgptandfine-tunedbert.arXivpreprint arXiv:2302.10198 (2023) [111] Zhou, C., Qiu, C., Acuna, D.E.: Paraphrase identification with deep learning: A review of datasets and methods. arXiv preprint arXiv:2212.06933 (2022) [112] Zhuo, T.Y., Huang, Y., Chen, C., Xing, Z.: Exploring ai ethics of chatgpt: A diagnostic analysis. arXiv preprint arXiv:2301.12867 (2023) Yiheng Liu et al.: Preprint submitted to Elsevier Page 21 of 21

